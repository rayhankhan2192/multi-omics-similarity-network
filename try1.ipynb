{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "#!pip install torch\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "cuda = True if torch.cuda.is_available() else False\n",
    "print(cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_sample_weight(labels, num_class, use_sample_weight=True):\n",
    "    if not use_sample_weight:\n",
    "        return np.ones(len(labels)) / len(labels)\n",
    "    count = np.zeros(num_class)\n",
    "    for i in range(num_class):\n",
    "        count[i] = np.sum(labels==i)\n",
    "    sample_weight = np.zeros(labels.shape)\n",
    "    for i in range(num_class):\n",
    "        sample_weight[np.where(labels==i)[0]] = count[i]/np.sum(count)\n",
    "    \n",
    "    return sample_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_tensor(y, num_dim):\n",
    "    y_onehot = torch.zeros(y.shape[0], num_dim)\n",
    "    y_onehot.scatter_(1, y.view(-1,1), 1)\n",
    "    \n",
    "    return y_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_distance_torch(x1, x2=None, eps=1e-8):\n",
    "    x2 = x1 if x2 is None else x2\n",
    "    w1 = x1.norm(p=2, dim=1, keepdim=True)\n",
    "    w2 = w1 if x2 is x1 else x2.norm(p=2, dim=1, keepdim=True)\n",
    "    return 1 - torch.mm(x1, x2.t()) / (w1 * w2.t()).clamp(min=eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_sparse(x):\n",
    "    x_typename = torch.typename(x).split('.')[-1]\n",
    "    sparse_tensortype = getattr(torch.sparse, x_typename)\n",
    "    indices = torch.nonzero(x)\n",
    "    if len(indices.shape) == 0:  # if all elements are zeros\n",
    "        return sparse_tensortype(*x.shape)\n",
    "    indices = indices.t()\n",
    "    values = x[tuple(indices[i] for i in range(indices.shape[0]))]\n",
    "    return sparse_tensortype(indices, values, x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def cal_adj_mat_parameter(edge_per_node, data, metric=\"cosine\"):\n",
    "    #assert metric == \"cosine\", \"Only cosine distance implemented\"\n",
    "    #dist = cosine_distance_torch(data, data)\n",
    "    #parameter = torch.sort(dist.reshape(-1,)).values[edge_per_node*data.shape[0]]\n",
    "    #return np.asscalar(parameter.data.cpu().numpy())\n",
    "    #return parameter.data.cpu().numpy().item()\n",
    "def cal_adj_mat_parameter(adj_parameter, data, metric):\n",
    "    assert metric == \"cosine\", \"Only cosine distance implemented\"\n",
    "    dist = cosine_distance_torch(data, data)\n",
    "    edge_per_node = int(adj_parameter * data.shape[0])  # Convert to integer\n",
    "    parameter = torch.sort(dist.reshape(-1,)).values[edge_per_node]\n",
    "    return parameter.data.cpu().numpy().item()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_from_dist_tensor(dist, parameter, self_dist=True):\n",
    "    if self_dist:\n",
    "        assert dist.shape[0]==dist.shape[1], \"Input is not pairwise dist matrix\"\n",
    "    g = (dist <= parameter).float()\n",
    "    if self_dist:\n",
    "        diag_idx = np.diag_indices(g.shape[0])\n",
    "        g[diag_idx[0], diag_idx[1]] = 0\n",
    "        \n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_adj_mat_tensor(data, parameter, metric=\"cosine\"):\n",
    "    assert metric == \"cosine\", \"Only cosine distance implemented\"\n",
    "    dist = cosine_distance_torch(data, data)\n",
    "    g = graph_from_dist_tensor(dist, parameter, self_dist=True)\n",
    "    adj = 1-dist if metric == \"cosine\" else NotImplementedError\n",
    "    adj = adj * g\n",
    "    adj_T = adj.transpose(0,1)\n",
    "    I = torch.eye(adj.shape[0]).cuda() if cuda else torch.eye(adj.shape[0])\n",
    "    adj = adj + adj_T*(adj_T > adj).float() - adj*(adj_T > adj).float()\n",
    "    adj = F.normalize(adj + I, p=1)\n",
    "    adj = to_sparse(adj)\n",
    "    \n",
    "    return adj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_test_adj_mat_tensor(data, trte_idx, parameter, metric=\"cosine\"):\n",
    "    assert metric == \"cosine\", \"Only cosine distance implemented\"\n",
    "    adj = torch.zeros((data.shape[0], data.shape[0]))\n",
    "    if cuda:\n",
    "        adj = adj.cuda()\n",
    "    num_tr = len(trte_idx[\"tr\"])\n",
    "    \n",
    "    dist_tr2te = cosine_distance_torch(data[trte_idx[\"tr\"]], data[trte_idx[\"te\"]])\n",
    "    g_tr2te = graph_from_dist_tensor(dist_tr2te, parameter, self_dist=False)\n",
    "    if metric == \"cosine\":\n",
    "        adj[:num_tr,num_tr:] = 1-dist_tr2te\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    adj[:num_tr,num_tr:] = adj[:num_tr,num_tr:]*g_tr2te\n",
    "    \n",
    "    dist_te2tr = cosine_distance_torch(data[trte_idx[\"te\"]], data[trte_idx[\"tr\"]])\n",
    "    g_te2tr = graph_from_dist_tensor(dist_te2tr, parameter, self_dist=False)\n",
    "    if metric == \"cosine\":\n",
    "        adj[num_tr:,:num_tr] = 1-dist_te2tr\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    adj[num_tr:,:num_tr] = adj[num_tr:,:num_tr]*g_te2tr # retain selected edges\n",
    "    \n",
    "    adj_T = adj.transpose(0,1)\n",
    "    I = torch.eye(adj.shape[0])\n",
    "    if cuda:\n",
    "        I = I.cuda()\n",
    "    adj = adj + adj_T*(adj_T > adj).float() - adj*(adj_T > adj).float()\n",
    "    adj = F.normalize(adj + I, p=1)\n",
    "    adj = to_sparse(adj)\n",
    "    \n",
    "    return adj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xavier_init(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.xavier_normal_(m.weight)\n",
    "        if m.bias is not None:\n",
    "           m.bias.data.fill_(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphConvolution(nn.Module):\n",
    "    def __init__(self, in_features, out_features, bias=True):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(in_features, out_features))\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.FloatTensor(out_features))\n",
    "        nn.init.xavier_normal_(self.weight.data)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.fill_(0.0)\n",
    "            \n",
    "    def forward(self, input, adj):\n",
    "        support = torch.mm(input, self.weight)\n",
    "        output = torch.sparse.mm(adj, support)\n",
    "        if self.bias is not None:\n",
    "            return output + self.bias\n",
    "        else:\n",
    "            return output    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN_E(nn.Module):\n",
    "    def __init__(self, in_dim, hgcn_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.gc1 = GraphConvolution(in_dim, hgcn_dim[0])\n",
    "        self.gc2 = GraphConvolution(hgcn_dim[0], hgcn_dim[1])\n",
    "        self.gc3 = GraphConvolution(hgcn_dim[1], hgcn_dim[2])\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        x = self.gc1(x, adj)\n",
    "        x = F.leaky_relu(x, 0.25)\n",
    "        x = F.dropout(x, self.dropout, training=self.training)\n",
    "        x = self.gc2(x, adj)\n",
    "        x = F.leaky_relu(x, 0.25)\n",
    "        x = F.dropout(x, self.dropout, training=self.training)\n",
    "        x = self.gc3(x, adj)\n",
    "        x = F.leaky_relu(x, 0.25)\n",
    "        \n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier_1(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.clf = nn.Sequential(nn.Linear(in_dim, out_dim))\n",
    "        self.clf.apply(xavier_init)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.clf(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VCDN(nn.Module):\n",
    "    def __init__(self, num_view, num_cls, hvcdn_dim):\n",
    "        super().__init__()\n",
    "        self.num_cls = num_cls\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(pow(num_cls, num_view), hvcdn_dim),\n",
    "            nn.LeakyReLU(0.25),\n",
    "            nn.Linear(hvcdn_dim, num_cls)\n",
    "        )\n",
    "        self.model.apply(xavier_init)\n",
    "        \n",
    "    def forward(self, in_list):\n",
    "        num_view = len(in_list)\n",
    "        for i in range(num_view):\n",
    "            in_list[i] = torch.sigmoid(in_list[i])\n",
    "        x = torch.reshape(torch.matmul(in_list[0].unsqueeze(-1), in_list[1].unsqueeze(1)),(-1,pow(self.num_cls,2),1))\n",
    "        for i in range(2,num_view):\n",
    "            x = torch.reshape(torch.matmul(x, in_list[i].unsqueeze(1)),(-1,pow(self.num_cls,i+1),1))\n",
    "        vcdn_feat = torch.reshape(x, (-1,pow(self.num_cls,num_view)))\n",
    "        output = self.model(vcdn_feat)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model_dict(num_view, num_class, dim_list, dim_he_list, dim_hc, gcn_dopout=0.5):\n",
    "    model_dict = {}\n",
    "    for i in range(num_view):\n",
    "        model_dict[\"E{:}\".format(i+1)] = GCN_E(dim_list[i], dim_he_list, gcn_dopout)\n",
    "        model_dict[\"C{:}\".format(i+1)] = Classifier_1(dim_he_list[-1], num_class)\n",
    "    if num_view >= 2:\n",
    "        model_dict[\"C\"] = VCDN(num_view, num_class, dim_hc)\n",
    "    return model_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_optim(num_view, model_dict, lr_e=1e-4, lr_c=1e-4):\n",
    "    optim_dict = {}\n",
    "    for i in range(num_view):\n",
    "        optim_dict[\"C{:}\".format(i+1)] = torch.optim.Adam(\n",
    "                list(model_dict[\"E{:}\".format(i+1)].parameters())+list(model_dict[\"C{:}\".format(i+1)].parameters()), \n",
    "                lr=lr_e)\n",
    "    if num_view >= 2:\n",
    "        optim_dict[\"C\"] = torch.optim.Adam(model_dict[\"C\"].parameters(), lr=lr_c)\n",
    "    return optim_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prepare_trte_data(data_folder, view_list):\n",
    "    num_view = len(view_list)\n",
    "    \n",
    "    labels_tr = np.loadtxt(os.path.join(data_folder, \"labels_tr.csv\"), delimiter=',')\n",
    "    labels_te = np.loadtxt(os.path.join(data_folder, \"labels_te.csv\"), delimiter=',')\n",
    "    labels_tr = labels_tr.astype(int)\n",
    "    labels_te = labels_te.astype(int)\n",
    "    data_tr_list = []\n",
    "    data_te_list = []\n",
    "    for i in view_list:\n",
    "        data_tr_list.append(np.loadtxt(os.path.join(data_folder, str(i)+\"_tr.csv\"), delimiter=','))\n",
    "        data_te_list.append(np.loadtxt(os.path.join(data_folder, str(i)+\"_te.csv\"), delimiter=','))\n",
    "    num_tr = data_tr_list[0].shape[0]\n",
    "    num_te = data_te_list[0].shape[0]\n",
    "    data_mat_list = []\n",
    "    for i in range(num_view):\n",
    "        data_mat_list.append(np.concatenate((data_tr_list[i], data_te_list[i]), axis=0))\n",
    "    data_tensor_list = []\n",
    "    for i in range(len(data_mat_list)):\n",
    "        data_tensor_list.append(torch.FloatTensor(data_mat_list[i]))\n",
    "        if cuda:\n",
    "            data_tensor_list[i] = data_tensor_list[i].cuda()\n",
    "    idx_dict = {}\n",
    "    idx_dict[\"tr\"] = list(range(num_tr))\n",
    "    idx_dict[\"te\"] = list(range(num_tr, (num_tr+num_te)))\n",
    "    data_train_list = []\n",
    "    data_all_list = []\n",
    "    for i in range(len(data_tensor_list)):\n",
    "        data_train_list.append(data_tensor_list[i][idx_dict[\"tr\"]].clone())\n",
    "        data_all_list.append(torch.cat((data_tensor_list[i][idx_dict[\"tr\"]].clone(),\n",
    "                                       data_tensor_list[i][idx_dict[\"te\"]].clone()),0))\n",
    "    labels = np.concatenate((labels_tr, labels_te))\n",
    "    \n",
    "    return data_train_list, data_all_list, idx_dict, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_tr_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[106], line 109\u001b[0m\n\u001b[0;32m    106\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m adj_train_list, adj_test_list\n\u001b[0;32m    108\u001b[0m \u001b[38;5;66;03m# Example usage (assuming required functions and data are defined):\u001b[39;00m\n\u001b[1;32m--> 109\u001b[0m adj_train_list, adj_test_list \u001b[38;5;241m=\u001b[39m gen_trte_adj_mat(\u001b[43mdata_tr_list\u001b[49m, data_trte_list, trte_idx, adj_parameter)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;66;03m# Example usage:\u001b[39;00m\n\u001b[0;32m    115\u001b[0m data_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset_rosmap\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Change this to the actual path\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data_tr_list' is not defined"
     ]
    }
   ],
   "source": [
    "def prepare_trte_data(data_folder, view_list):\n",
    "    num_view = len(view_list)\n",
    "    labels_tr = np.loadtxt(os.path.join(data_folder, \"labels_tr.csv\"), delimiter=',')\n",
    "    labels_te = np.loadtxt(os.path.join(data_folder, \"labels_te.csv\"), delimiter=',')\n",
    "    labels_tr = labels_tr.astype(int)\n",
    "    labels_te = labels_te.astype(int)\n",
    "    print(\"Number of views: \", num_view)\n",
    "    print(\"Training Labels:\", len(labels_tr))\n",
    "    print(\"Testing Labels:\", len(labels_te))\n",
    "    \n",
    "    data_tr_list = []\n",
    "    data_te_list = []\n",
    "    for i in view_list:\n",
    "        tr_data = np.loadtxt(os.path.join(data_folder, str(i)+\"_tr.csv\"), delimiter=',')\n",
    "        te_data = np.loadtxt(os.path.join(data_folder, str(i)+\"_te.csv\"), delimiter=',')\n",
    "        data_tr_list.append(tr_data)\n",
    "        data_te_list.append(te_data)\n",
    "        print(f\"View {i} Training Data Shape:\", tr_data.shape)\n",
    "        print(f\"View {i} Testing Data Shape:\", te_data.shape)\n",
    "    \n",
    "    \n",
    "    num_tr = data_tr_list[0].shape[0]\n",
    "    num_te = data_te_list[0].shape[0]\n",
    "    \n",
    "    data_mat_list = []\n",
    "    for i in range(num_view):\n",
    "        combined_data = np.concatenate((data_tr_list[i], data_te_list[i]), axis=0)\n",
    "        data_mat_list.append(combined_data)\n",
    "        #df = pd.DataFrame(combined_data)\n",
    "        #df.to_csv(f\"view_{view_list[i]}_combined.csv\", index=False, header=False)\n",
    "        #print(f\"Saved View {view_list[i]} Combined Data to view_{view_list[i]}_combined.csv\")\n",
    "        #df.to_csv(f\"combined_data_view_{view_list[i]}.csv\", index=False)\n",
    "        #print(f\"Saved Combined Data to combined_data_view_{view_list[i]}.csv\")\n",
    "        print(f\"View {view_list[i]} Combined Data Shape:\", combined_data.shape)\n",
    "    \n",
    "    \n",
    "    data_tensor_list = []\n",
    "    cuda = torch.cuda.is_available()\n",
    "    for i in range(len(data_mat_list)):\n",
    "        tensor_data = torch.FloatTensor(data_mat_list[i])\n",
    "        if cuda:\n",
    "            tensor_data = tensor_data.cuda()\n",
    "        data_tensor_list.append(tensor_data)\n",
    "        print(f\"View {view_list[i]} Tensor Data Shape:\", tensor_data.shape)\n",
    "    # Convert tensor to CPU, then NumPy\n",
    "    #tensor_cpu = tensor_data.cpu().numpy()\n",
    "    # Convert to DataFrame and save as CSV\n",
    "    #df = pd.DataFrame(tensor_cpu)\n",
    "    #df.to_csv(f\"tensor_view_{view_list[i]}.csv\", index=False)\n",
    "    #print(f\"Saved View {view_list[i]} Tensor Data to tensor_view_{view_list[i]}.csv\")\n",
    "\n",
    "    idx_dict = {}\n",
    "    idx_dict[\"tr\"]= list(range(num_tr)),\n",
    "    idx_dict[\"te\"]= list(range(num_tr, (num_tr + num_te)))\n",
    "    print(\"Index Dictionary:\", idx_dict[\"tr\"])\n",
    "    print(\"Index Dictionary:\", idx_dict[\"te\"])\n",
    "    \n",
    "    #data_train_list = [data_tensor_list[i][idx_dict[\"tr\"]].clone() for i in range(len(data_tensor_list))]\n",
    "    #data_all_list = [torch.cat((data_tensor_list[i][idx_dict[\"tr\"]].clone(), data_tensor_list[i][idx_dict[\"te\"]].clone()), 0) for i in range(len(data_tensor_list))]\n",
    "    \n",
    "    data_train_list = []\n",
    "    data_all_list = []\n",
    "    for i in range(len(data_tensor_list)):\n",
    "        data_train_list.append(data_tensor_list[i][idx_dict[\"tr\"]].clone())\n",
    "        data_all_list.append(torch.cat((data_tensor_list[i][idx_dict[\"tr\"]].clone(),\n",
    "                                       data_tensor_list[i][idx_dict[\"te\"]].clone()),0))\n",
    "    for i in range(len(data_tensor_list)):\n",
    "        #print(f\"\\n=== View {i} ===\")\n",
    "        #print(\"\\nTrain Data:\")\n",
    "        #print(data_train_list[i])  # Prints the training tensor for the current view\n",
    "        #print(\"\\nAll Data (Train + Test):\")\n",
    "        #print(data_all_list[i])  # Prints the full dataset (train + test) tensor for the current view\n",
    "        #print(\"=\" * 40)  # Separator for better readability\n",
    "        train_data_np = data_train_list[i].cpu().numpy()\n",
    "        all_data_np = data_all_list[i].cpu().numpy()\n",
    "        # Create DataFrames\n",
    "        train_df = pd.DataFrame(train_data_np)\n",
    "        all_df = pd.DataFrame(all_data_np)\n",
    "        # Save DataFrames to CSV\n",
    "        train_df.to_csv(f\"view_{i}_train_data.csv\", index=False, header=False)\n",
    "        all_df.to_csv(f\"view_{i}_all_data.csv\", index=False, header=False)\n",
    "        #print(f\"Saved View {i} Train Data to view_{i}_train_data.csv\")\n",
    "        #print(f\"Saved View {i} All Data to view_{i}_all_data.csv\")\n",
    "    labels = np.concatenate((labels_tr, labels_te))\n",
    "    #print(\"Final Labels:\", labels)\n",
    "    return data_train_list, data_all_list, idx_dict, labels\n",
    "def gen_trte_adj_mat(data_tr_list, data_trte_list, trte_idx, adj_parameter):\n",
    "    adj_metric = \"cosine\"  # cosine distance\n",
    "    adj_train_list = []\n",
    "    adj_test_list = []\n",
    "    \n",
    "    for i in range(len(data_tr_list)):\n",
    "        print(f\"Processing View {i+1}...\")\n",
    "        \n",
    "        adj_parameter_adaptive = cal_adj_mat_parameter(adj_parameter, data_tr_list[i], adj_metric)\n",
    "        print(f\"Adaptive Adjacency Parameter for View {i+1}: {adj_parameter_adaptive}\")\n",
    "        \n",
    "        adj_train = gen_adj_mat_tensor(data_tr_list[i], adj_parameter_adaptive, adj_metric)\n",
    "        adj_train_list.append(adj_train)\n",
    "        print(f\"Adjacency Matrix (Train) for View {i+1}:\\n\", adj_train)\n",
    "        \n",
    "        adj_test = gen_test_adj_mat_tensor(data_trte_list[i], trte_idx, adj_parameter_adaptive, adj_metric)\n",
    "        adj_test_list.append(adj_test)\n",
    "        print(f\"Adjacency Matrix (Test) for View {i+1}:\\n\", adj_test)\n",
    "        \n",
    "    return adj_train_list, adj_test_list\n",
    "\n",
    "# Example usage (assuming required functions and data are defined):\n",
    "adj_train_list, adj_test_list = gen_trte_adj_mat(data_tr_list, data_trte_list, trte_idx, adj_parameter)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "# Example usage:\n",
    "data_folder = \"dataset_rosmap\"  # Change this to the actual path\n",
    "view_list = [1, 2, 3]  # Modify based on available views\n",
    "data_train_list, data_all_list, idx_dict, labels = prepare_trte_data(data_folder, view_list)\n",
    "\n",
    "# Print final outputs\n",
    "print(\"Data Train List Length:\", len(data_train_list))\n",
    "print(\"Data All List Length:\", len(data_all_list))\n",
    "print(\"Index Dictionary:\", idx_dict)\n",
    "print(\"Labels Shape:\", labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport os\\nimport numpy as np\\nimport pandas as pd\\nimport torch\\n\\ndef prepare_trte_data(data_folder, view_list):\\n    num_view = len(view_list)\\n    labels_tr = np.loadtxt(os.path.join(data_folder, \"labels_tr.csv\"), delimiter=\\',\\')\\n    labels_te = np.loadtxt(os.path.join(data_folder, \"labels_te.csv\"), delimiter=\\',\\')\\n    labels_tr = labels_tr.astype(int)\\n    labels_te = labels_te.astype(int)\\n    \\n    data_tr_list = []\\n    data_te_list = []\\n    for i in view_list:\\n        tr_data = np.loadtxt(os.path.join(data_folder, f\"{i}_tr.csv\"), delimiter=\\',\\')\\n        te_data = np.loadtxt(os.path.join(data_folder, f\"{i}_te.csv\"), delimiter=\\',\\')\\n        data_tr_list.append(tr_data)\\n        data_te_list.append(te_data)\\n        print(f\"View {i} Training Data Shape:\", tr_data.shape)\\n        print(f\"View {i} Testing Data Shape:\", te_data.shape)\\n    \\n    num_tr = data_tr_list[0].shape[0]\\n    num_te = data_te_list[0].shape[0]\\n    \\n    data_mat_list = []\\n    for i in range(num_view):\\n        combined_data = np.concatenate((data_tr_list[i], data_te_list[i]), axis=0)\\n        data_mat_list.append(combined_data)\\n    \\n    data_tensor_list = []\\n    cuda = torch.cuda.is_available()\\n    for i in range(len(data_mat_list)):\\n        tensor_data = torch.FloatTensor(data_mat_list[i])\\n        if cuda:\\n            tensor_data = tensor_data.cuda()\\n        data_tensor_list.append(tensor_data)\\n        print(f\"View {view_list[i]} Tensor Data Shape:\", tensor_data.shape)\\n        \\n        # Convert tensor to CPU, then NumPy and save as CSV\\n        tensor_cpu = tensor_data.cpu().numpy()\\n        df = pd.DataFrame(tensor_cpu)\\n        df.to_csv(f\"tensor_view_{view_list[i]}.csv\", index=False)\\n        print(f\"Saved View {view_list[i]} Tensor Data to tensor_view_{view_list[i]}.csv\")\\n    \\n    idx_dict = {\"tr\": list(range(num_tr)), \"te\": list(range(num_tr, num_tr + num_te))}\\n    \\n    data_train_list = []\\n    data_all_list = []\\n    for i in range(len(data_tensor_list)):\\n        data_train_list.append(data_tensor_list[i][idx_dict[\"tr\"]].clone())\\n        data_all_list.append(torch.cat((data_tensor_list[i][idx_dict[\"tr\"]].clone(),\\n                                       data_tensor_list[i][idx_dict[\"te\"]].clone()), 0))\\n        \\n        train_data_np = data_train_list[i].cpu().numpy()\\n        all_data_np = data_all_list[i].cpu().numpy()\\n        \\n        # Save train and all data as CSV\\n        train_df = pd.DataFrame(train_data_np)\\n        all_df = pd.DataFrame(all_data_np)\\n        train_df.to_csv(f\"view_{view_list[i]}_train_data.csv\", index=False, header=False)\\n        all_df.to_csv(f\"view_{view_list[i]}_all_data.csv\", index=False, header=False)\\n        print(f\"Saved View {view_list[i]} Train Data to view_{view_list[i]}_train_data.csv\")\\n        print(f\"Saved View {view_list[i]} All Data to view_{view_list[i]}_all_data.csv\")\\n    \\n    labels = np.concatenate((labels_tr, labels_te))\\n    return data_train_list, data_all_list, idx_dict, labels\\n\\n# Example usage:\\ndata_folder = \"dataset_rosmap\"  # Change this to the actual path\\nview_list = [1, 2, 3]  # Modify based on available views\\ndata_train_list, data_all_list, idx_dict, labels = prepare_trte_data(data_folder, view_list)\\n'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "def prepare_trte_data(data_folder, view_list):\n",
    "    num_view = len(view_list)\n",
    "    labels_tr = np.loadtxt(os.path.join(data_folder, \"labels_tr.csv\"), delimiter=',')\n",
    "    labels_te = np.loadtxt(os.path.join(data_folder, \"labels_te.csv\"), delimiter=',')\n",
    "    labels_tr = labels_tr.astype(int)\n",
    "    labels_te = labels_te.astype(int)\n",
    "    \n",
    "    data_tr_list = []\n",
    "    data_te_list = []\n",
    "    for i in view_list:\n",
    "        tr_data = np.loadtxt(os.path.join(data_folder, f\"{i}_tr.csv\"), delimiter=',')\n",
    "        te_data = np.loadtxt(os.path.join(data_folder, f\"{i}_te.csv\"), delimiter=',')\n",
    "        data_tr_list.append(tr_data)\n",
    "        data_te_list.append(te_data)\n",
    "        print(f\"View {i} Training Data Shape:\", tr_data.shape)\n",
    "        print(f\"View {i} Testing Data Shape:\", te_data.shape)\n",
    "    \n",
    "    num_tr = data_tr_list[0].shape[0]\n",
    "    num_te = data_te_list[0].shape[0]\n",
    "    \n",
    "    data_mat_list = []\n",
    "    for i in range(num_view):\n",
    "        combined_data = np.concatenate((data_tr_list[i], data_te_list[i]), axis=0)\n",
    "        data_mat_list.append(combined_data)\n",
    "    \n",
    "    data_tensor_list = []\n",
    "    cuda = torch.cuda.is_available()\n",
    "    for i in range(len(data_mat_list)):\n",
    "        tensor_data = torch.FloatTensor(data_mat_list[i])\n",
    "        if cuda:\n",
    "            tensor_data = tensor_data.cuda()\n",
    "        data_tensor_list.append(tensor_data)\n",
    "        print(f\"View {view_list[i]} Tensor Data Shape:\", tensor_data.shape)\n",
    "        \n",
    "        # Convert tensor to CPU, then NumPy and save as CSV\n",
    "        tensor_cpu = tensor_data.cpu().numpy()\n",
    "        df = pd.DataFrame(tensor_cpu)\n",
    "        df.to_csv(f\"tensor_view_{view_list[i]}.csv\", index=False)\n",
    "        print(f\"Saved View {view_list[i]} Tensor Data to tensor_view_{view_list[i]}.csv\")\n",
    "    \n",
    "    idx_dict = {\"tr\": list(range(num_tr)), \"te\": list(range(num_tr, num_tr + num_te))}\n",
    "    \n",
    "    data_train_list = []\n",
    "    data_all_list = []\n",
    "    for i in range(len(data_tensor_list)):\n",
    "        data_train_list.append(data_tensor_list[i][idx_dict[\"tr\"]].clone())\n",
    "        data_all_list.append(torch.cat((data_tensor_list[i][idx_dict[\"tr\"]].clone(),\n",
    "                                       data_tensor_list[i][idx_dict[\"te\"]].clone()), 0))\n",
    "        \n",
    "        train_data_np = data_train_list[i].cpu().numpy()\n",
    "        all_data_np = data_all_list[i].cpu().numpy()\n",
    "        \n",
    "        # Save train and all data as CSV\n",
    "        train_df = pd.DataFrame(train_data_np)\n",
    "        all_df = pd.DataFrame(all_data_np)\n",
    "        train_df.to_csv(f\"view_{view_list[i]}_train_data.csv\", index=False, header=False)\n",
    "        all_df.to_csv(f\"view_{view_list[i]}_all_data.csv\", index=False, header=False)\n",
    "        print(f\"Saved View {view_list[i]} Train Data to view_{view_list[i]}_train_data.csv\")\n",
    "        print(f\"Saved View {view_list[i]} All Data to view_{view_list[i]}_all_data.csv\")\n",
    "    \n",
    "    labels = np.concatenate((labels_tr, labels_te))\n",
    "    return data_train_list, data_all_list, idx_dict, labels\n",
    "\n",
    "# Example usage:\n",
    "data_folder = \"dataset_rosmap\"  # Change this to the actual path\n",
    "view_list = [1, 2, 3]  # Modify based on available views\n",
    "data_train_list, data_all_list, idx_dict, labels = prepare_trte_data(data_folder, view_list)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_trte_adj_mat(data_tr_list, data_trte_list, trte_idx, adj_parameter):\n",
    "    adj_metric = \"cosine\" # cosine distance\n",
    "    adj_train_list = []\n",
    "    adj_test_list = []\n",
    "    for i in range(len(data_tr_list)):\n",
    "        adj_parameter_adaptive = cal_adj_mat_parameter(adj_parameter, data_tr_list[i], adj_metric)\n",
    "        adj_train_list.append(gen_adj_mat_tensor(data_tr_list[i], adj_parameter_adaptive, adj_metric))\n",
    "        adj_test_list.append(gen_test_adj_mat_tensor(data_trte_list[i], trte_idx, adj_parameter_adaptive, adj_metric))\n",
    "    \n",
    "    return adj_train_list, adj_test_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(data_list, adj_list, label, one_hot_tensor, sample_weight, model_dict, optim_dict, train_VCDN=True):\n",
    "    loss_dict = {}\n",
    "    criterion = torch.nn.CrossEntropyLoss(reduction='none')\n",
    "    for m in model_dict:\n",
    "        model_dict[m].train()    \n",
    "    num_view = len(data_list)\n",
    "    for i in range(num_view):\n",
    "        optim_dict[\"C{:}\".format(i+1)].zero_grad()\n",
    "        ci_loss = 0\n",
    "        ci = model_dict[\"C{:}\".format(i+1)](model_dict[\"E{:}\".format(i+1)](data_list[i],adj_list[i]))\n",
    "        ci_loss = torch.mean(torch.mul(criterion(ci, label),sample_weight))\n",
    "        ci_loss.backward()\n",
    "        optim_dict[\"C{:}\".format(i+1)].step()\n",
    "        loss_dict[\"C{:}\".format(i+1)] = ci_loss.detach().cpu().numpy().item()\n",
    "    if train_VCDN and num_view >= 2:\n",
    "        optim_dict[\"C\"].zero_grad()\n",
    "        c_loss = 0\n",
    "        ci_list = []\n",
    "        for i in range(num_view):\n",
    "            ci_list.append(model_dict[\"C{:}\".format(i+1)](model_dict[\"E{:}\".format(i+1)](data_list[i],adj_list[i])))\n",
    "        c = model_dict[\"C\"](ci_list)    \n",
    "        c_loss = torch.mean(torch.mul(criterion(c, label),sample_weight))\n",
    "        c_loss.backward()\n",
    "        optim_dict[\"C\"].step()\n",
    "        loss_dict[\"C\"] = c_loss.detach().cpu().numpy().item()\n",
    "    \n",
    "    return loss_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_epoch(data_list, adj_list, te_idx, model_dict):\n",
    "    for m in model_dict:\n",
    "        model_dict[m].eval()\n",
    "    num_view = len(data_list)\n",
    "    ci_list = []\n",
    "    for i in range(num_view):\n",
    "        ci_list.append(model_dict[\"C{:}\".format(i+1)](model_dict[\"E{:}\".format(i+1)](data_list[i],adj_list[i])))\n",
    "    if num_view >= 2:\n",
    "        c = model_dict[\"C\"](ci_list)    \n",
    "    else:\n",
    "        c = ci_list[0]\n",
    "    c = c[te_idx,:]\n",
    "    prob = F.softmax(c, dim=1).data.cpu().numpy()\n",
    "    \n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(data_folder, view_list, num_class,\n",
    "               lr_e_pretrain, lr_e, lr_c, \n",
    "               num_epoch_pretrain, num_epoch):\n",
    "    test_inverval = 50\n",
    "    num_view = len(view_list)\n",
    "    dim_hvcdn = pow(num_class,num_view)\n",
    "    if data_folder == 'dataset_rosmap':\n",
    "        adj_parameter = 2\n",
    "        dim_he_list = [200,200,100]\n",
    "    #if data_folder == 'BRCA':\n",
    "     #   adj_parameter = 10\n",
    "      #  dim_he_list = [400,400,200]\n",
    "    data_tr_list, data_trte_list, trte_idx, labels_trte = prepare_trte_data(data_folder, view_list)\n",
    "    labels_tr_tensor = torch.LongTensor(labels_trte[trte_idx[\"tr\"]])\n",
    "    onehot_labels_tr_tensor = one_hot_tensor(labels_tr_tensor, num_class)\n",
    "    sample_weight_tr = cal_sample_weight(labels_trte[trte_idx[\"tr\"]], num_class)\n",
    "    sample_weight_tr = torch.FloatTensor(sample_weight_tr)\n",
    "    if cuda:\n",
    "        labels_tr_tensor = labels_tr_tensor.cuda()\n",
    "        onehot_labels_tr_tensor = onehot_labels_tr_tensor.cuda()\n",
    "        sample_weight_tr = sample_weight_tr.cuda()\n",
    "    adj_tr_list, adj_te_list = gen_trte_adj_mat(data_tr_list, data_trte_list, trte_idx, adj_parameter)\n",
    "    dim_list = [x.shape[1] for x in data_tr_list]\n",
    "    model_dict = init_model_dict(num_view, num_class, dim_list, dim_he_list, dim_hvcdn)\n",
    "    for m in model_dict:\n",
    "        if cuda:\n",
    "            model_dict[m].cuda()\n",
    "    \n",
    "    print(\"\\nPretrain GCNs...\")\n",
    "    optim_dict = init_optim(num_view, model_dict, lr_e_pretrain, lr_c)\n",
    "    for epoch in range(num_epoch_pretrain):\n",
    "        train_epoch(data_tr_list, adj_tr_list, labels_tr_tensor, \n",
    "                    onehot_labels_tr_tensor, sample_weight_tr, model_dict, optim_dict, train_VCDN=False)\n",
    "    print(\"\\nTraining...\")\n",
    "    optim_dict = init_optim(num_view, model_dict, lr_e, lr_c)\n",
    "    for epoch in range(num_epoch+1):\n",
    "        train_epoch(data_tr_list, adj_tr_list, labels_tr_tensor, \n",
    "                    onehot_labels_tr_tensor, sample_weight_tr, model_dict, optim_dict)\n",
    "        if epoch % test_inverval == 0:\n",
    "            te_prob = test_epoch(data_trte_list, adj_te_list, trte_idx[\"te\"], model_dict)\n",
    "            print(\"\\nTest: Epoch {:d}\".format(epoch))\n",
    "            if num_class == 2:\n",
    "                print(\"Test ACC: {:.3f}\".format(accuracy_score(labels_trte[trte_idx[\"te\"]], te_prob.argmax(1))))\n",
    "                print(\"Test F1: {:.3f}\".format(f1_score(labels_trte[trte_idx[\"te\"]], te_prob.argmax(1))))\n",
    "                print(\"Test AUC: {:.3f}\".format(roc_auc_score(labels_trte[trte_idx[\"te\"]], te_prob[:,1])))\n",
    "            else:\n",
    "                print(\"Test ACC: {:.3f}\".format(accuracy_score(labels_trte[trte_idx[\"te\"]], te_prob.argmax(1))))\n",
    "                print(\"Test F1 weighted: {:.3f}\".format(f1_score(labels_trte[trte_idx[\"te\"]], te_prob.argmax(1), average='weighted')))\n",
    "                print(\"Test F1 macro: {:.3f}\".format(f1_score(labels_trte[trte_idx[\"te\"]], te_prob.argmax(1), average='macro')))\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of views:  3\n",
      "Training Labels: 245\n",
      "Testing Labels: 106\n",
      "View 1 Training Data Shape: (245, 200)\n",
      "View 1 Testing Data Shape: (106, 200)\n",
      "View 2 Training Data Shape: (245, 200)\n",
      "View 2 Testing Data Shape: (106, 200)\n",
      "View 3 Training Data Shape: (245, 200)\n",
      "View 3 Testing Data Shape: (106, 200)\n",
      "View 1 Combined Data Shape: (351, 200)\n",
      "View 2 Combined Data Shape: (351, 200)\n",
      "View 3 Combined Data Shape: (351, 200)\n",
      "View 1 Tensor Data Shape: torch.Size([351, 200])\n",
      "View 2 Tensor Data Shape: torch.Size([351, 200])\n",
      "View 3 Tensor Data Shape: torch.Size([351, 200])\n",
      "Index Dictionary: ([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244],)\n",
      "Index Dictionary: [245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (350) must match the existing size (106) at non-singleton dimension 1.  Target sizes: [1, 350].  Tensor sizes: [245, 106]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[103], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data_folder \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset_rosmap\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     12\u001b[0m     num_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m---> 14\u001b[0m \u001b[43mtrain_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mview_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m           \u001b[49m\u001b[43mlr_e_pretrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_c\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m           \u001b[49m\u001b[43mnum_epoch_pretrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epoch\u001b[49m\u001b[43m)\u001b[49m      \n",
      "Cell \u001b[1;32mIn[102], line 22\u001b[0m, in \u001b[0;36mtrain_test\u001b[1;34m(data_folder, view_list, num_class, lr_e_pretrain, lr_e, lr_c, num_epoch_pretrain, num_epoch)\u001b[0m\n\u001b[0;32m     20\u001b[0m     onehot_labels_tr_tensor \u001b[38;5;241m=\u001b[39m onehot_labels_tr_tensor\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[0;32m     21\u001b[0m     sample_weight_tr \u001b[38;5;241m=\u001b[39m sample_weight_tr\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m---> 22\u001b[0m adj_tr_list, adj_te_list \u001b[38;5;241m=\u001b[39m \u001b[43mgen_trte_adj_mat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_tr_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_trte_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrte_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madj_parameter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m dim_list \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m data_tr_list]\n\u001b[0;32m     24\u001b[0m model_dict \u001b[38;5;241m=\u001b[39m init_model_dict(num_view, num_class, dim_list, dim_he_list, dim_hvcdn)\n",
      "Cell \u001b[1;32mIn[99], line 8\u001b[0m, in \u001b[0;36mgen_trte_adj_mat\u001b[1;34m(data_tr_list, data_trte_list, trte_idx, adj_parameter)\u001b[0m\n\u001b[0;32m      6\u001b[0m     adj_parameter_adaptive \u001b[38;5;241m=\u001b[39m cal_adj_mat_parameter(adj_parameter, data_tr_list[i], adj_metric)\n\u001b[0;32m      7\u001b[0m     adj_train_list\u001b[38;5;241m.\u001b[39mappend(gen_adj_mat_tensor(data_tr_list[i], adj_parameter_adaptive, adj_metric))\n\u001b[1;32m----> 8\u001b[0m     adj_test_list\u001b[38;5;241m.\u001b[39mappend(\u001b[43mgen_test_adj_mat_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_trte_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrte_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madj_parameter_adaptive\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madj_metric\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m adj_train_list, adj_test_list\n",
      "Cell \u001b[1;32mIn[88], line 11\u001b[0m, in \u001b[0;36mgen_test_adj_mat_tensor\u001b[1;34m(data, trte_idx, parameter, metric)\u001b[0m\n\u001b[0;32m      9\u001b[0m g_tr2te \u001b[38;5;241m=\u001b[39m graph_from_dist_tensor(dist_tr2te, parameter, self_dist\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m metric \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcosine\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 11\u001b[0m     \u001b[43madj\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mnum_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnum_tr\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39mdist_tr2te\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The expanded size of the tensor (350) must match the existing size (106) at non-singleton dimension 1.  Target sizes: [1, 350].  Tensor sizes: [245, 106]"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":    \n",
    "    data_folder = 'dataset_rosmap'\n",
    "    view_list = [1,2,3]\n",
    "    num_epoch_pretrain = 500\n",
    "    num_epoch = 2500\n",
    "    lr_e_pretrain = 1e-3\n",
    "    lr_e = 5e-4\n",
    "    lr_c = 1e-3\n",
    "    adj_parameter = 0.1\n",
    "    \n",
    "    if data_folder == 'dataset_rosmap':\n",
    "        num_class = 2\n",
    "    \n",
    "    train_test(data_folder, view_list, num_class,\n",
    "               lr_e_pretrain, lr_e, lr_c, \n",
    "               num_epoch_pretrain, num_epoch)      "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

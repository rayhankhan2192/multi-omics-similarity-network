{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9ba52b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e05a4840",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(data):\n",
    "    mean = torch.mean(data, dim=0, keepdim=True)\n",
    "    std = torch.std(data, dim=0, keepdim=True)\n",
    "    std = torch.clamp(std, min=1e-8)\n",
    "    return (data - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bb0d8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_sample_weight(labels, num_class, use_sample_weight=True):\n",
    "    if not use_sample_weight:\n",
    "        return np.ones(len(labels)) / len(labels)\n",
    "    count = np.zeros(num_class)\n",
    "    for i in range(num_class):\n",
    "        count[i] = np.sum(labels==i)\n",
    "    sample_weight = np.zeros(labels.shape)\n",
    "    for i in range(num_class):\n",
    "        sample_weight[np.where(labels==i)[0]] = count[i]/np.sum(count)\n",
    "    \n",
    "    return sample_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ce540de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_tensor(y, num_dim):\n",
    "    y_onehot = torch.zeros(y.shape[0], num_dim)\n",
    "    y_onehot.scatter_(1, y.view(-1,1), 1)\n",
    "    \n",
    "    return y_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "144388f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_sparse(x):\n",
    "    x_typename = torch.typename(x).split('.')[-1]\n",
    "    sparse_tensortype = getattr(torch.sparse, x_typename)\n",
    "    indices = torch.nonzero(x)\n",
    "    if len(indices.shape) == 0:  # if all elements are zeros\n",
    "        return sparse_tensortype(*x.shape)\n",
    "    indices = indices.t()\n",
    "    values = x[tuple(indices[i] for i in range(indices.shape[0]))]\n",
    "    return sparse_tensortype(indices, values, x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fd045c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rbf_kernel(x1, x2=None, gamma=None):\n",
    "    \"\"\"\n",
    "    Radial Basis Function (Gaussian) Kernel as similarity.\n",
    "    \"\"\"\n",
    "    print(\"From rbf_kernel\")\n",
    "    x2 = x1 if x2 is None else x2\n",
    "    diff = x1.unsqueeze(1) - x2.unsqueeze(0)  # [N, M, D]\n",
    "    dist_sq = torch.sum(diff ** 2, dim=2)     # [N, M]\n",
    "    if gamma is None:\n",
    "        gamma = 1.0 / x1.shape[1]             # Default: 1 / num_features\n",
    "    sim = torch.exp(-gamma * dist_sq)\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4cfc4465",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaptive_rbf_distance_torch(x1, x2=None):\n",
    "    print(\"From adaptive_rbf_distance_torch\")\n",
    "    x2 = x1 if x2 is None else x2\n",
    "    # Compute median pairwise distance\n",
    "    x1_norm = (x1 ** 2).sum(dim=1).view(-1, 1)\n",
    "    x2_norm = x1_norm if x2 is x1 else (x2 ** 2).sum(dim=1).view(1, -1)\n",
    "    dist_squared = x1_norm + x2_norm - 2.0 * torch.mm(x1, x2.T)\n",
    "    median_dist = torch.median(dist_squared[dist_squared > 0])\n",
    "    gamma = 1.0 / (2.0 * median_dist)  # Adaptive gamma\n",
    "    sim = torch.exp(-gamma * dist_squared)\n",
    "    print(\"Sim: \",sim)\n",
    "    return 1 - sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcf779b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_distance_torch(x1, x2=None, eps=1e-8):\n",
    "    x2 = x1 if x2 is None else x2\n",
    "    w1 = x1.norm(p=2, dim=1, keepdim=True)\n",
    "    w2 = w1 if x2 is x1 else x2.norm(p=2, dim=1, keepdim=True)\n",
    "    res = 1 - torch.mm(x1, x2.t()) / (w1 * w2.t()).clamp(min=eps)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26a7bdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rbf_distance_torch(x1, x2=None, gamma=None):\n",
    "    \"\"\"\n",
    "    Computes RBF-based pairwise distances between samples.\n",
    "    The smaller the Euclidean distance, the higher the similarity (max=1).\n",
    "    \"\"\"\n",
    "    print(\"From rbf_distance_torch\")\n",
    "    x2 = x1 if x2 is None else x2\n",
    "    x1_norm = (x1 ** 2).sum(dim=1).view(-1, 1)\n",
    "    x2_norm = x1_norm if x2 is x1 else (x2 ** 2).sum(dim=1).view(1, -1)\n",
    "    \n",
    "    dist_squared = x1_norm + x2_norm - 2.0 * torch.mm(x1, x2.T)\n",
    "    dist_squared = torch.clamp(dist_squared, min=0.0)  # numerical safety\n",
    "    \n",
    "    if gamma is None:\n",
    "        median_dist = torch.median(dist_squared[dist_squared > 0])\n",
    "        gamma = 1.0 / (2.0 * median_dist)\n",
    "\n",
    "    sim = torch.exp(-gamma * dist_squared)  # RBF similarity\n",
    "    res = 1 - sim  # Return distance (small similarity -> larger distance)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d35130fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_similarity_torch(x1, x2=None, alpha=0.5, gamma=0.01):\n",
    "    print(\"Hybrid\")\n",
    "    x2 = x1 if x2 is None else x2\n",
    "    \n",
    "    # Calculate cosine similarity\n",
    "    cosine_sim = cosine_distance_torch(x1, x2)\n",
    "    \n",
    "    # Normalize cosine similarity to be in range [0, 1]\n",
    "    cosine_sim = torch.clamp(1 - cosine_sim, 0, 1)  # Cosine similarity is between 0 and 1\n",
    "    print(\"COS: \")\n",
    "    print(cosine_sim[:5, :5])\n",
    "    # Calculate RBF similarity\n",
    "    rbf_sim = rbf_distance_torch(x1, x2, gamma=gamma)\n",
    "    \n",
    "    # Normalize RBF similarity to be in range [0, 1] (if not already)\n",
    "    rbf_sim = torch.clamp(rbf_sim, 0, 1)\n",
    "    print(\"RBF: \")\n",
    "    print(rbf_sim[:5, :5])\n",
    "    alpha = cosine_sim.var() / (cosine_sim.var() + rbf_sim.var() + 1e-8)\n",
    "    print(\"Alpha: \", alpha)\n",
    "    # Combine similarities\n",
    "    hybrid_sim = alpha * cosine_sim + (1 - alpha) * rbf_sim\n",
    "    \n",
    "    # Ensure the hybrid similarity is within the range [0, 1]\n",
    "    hybrid_sim = torch.clamp(hybrid_sim, 0, 1)\n",
    "    hybrid_sim = F.normalize(hybrid_sim, p=1, dim=1)\n",
    "\n",
    "    print(\"\\nHybrid Similarity Matrix Shape:\", hybrid_sim.shape)\n",
    "    print(\"Hybrid Similarity Values (first 5x5):\")\n",
    "    print(hybrid_sim[:5, :5])\n",
    "    \n",
    "    return hybrid_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e36cdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cal_adj_mat_parameter(edge_per_node, data, metric=\"rbf\"):\n",
    "# def cal_adj_mat_parameter(edge_per_node, data, metric=\"cosine\"):\n",
    "# def cal_adj_mat_parameter(edge_per_node, data, metric=\"adaptive_rbf\"):\n",
    "def cal_adj_mat_parameter(edge_per_node, data, metric=\"hybrid\"):\n",
    "    assert metric in [\"rbf\", \"cosine\", \"adaptive_rbf\", \"hybrid\"], \"Only rbf, cosine, adaptive_rbf, and hybrid supported\"\n",
    "\n",
    "    if metric == \"rbf\":\n",
    "        dist = rbf_distance_torch(data, data, gamma=0.01)\n",
    "    elif metric == \"cosine\":\n",
    "        dist = cosine_distance_torch(data, data)\n",
    "    elif metric == \"adaptive_rbf\":\n",
    "        dist = adaptive_rbf_distance_torch(data, data)\n",
    "    elif metric == \"hybrid\":\n",
    "        dist = hybrid_similarity_torch(data, data, alpha=0.5, gamma=0.01)\n",
    "\n",
    "    parameter = torch.sort(dist.reshape(-1,)).values[edge_per_node*data.shape[0]]\n",
    "    return np.isscalar(parameter.data.cpu().numpy())\n",
    "    #return parameter.item()  # Return the scalar value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51a47562",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_from_dist_tensor(dist, parameter, self_dist=True):\n",
    "    if self_dist:\n",
    "        assert dist.shape[0]==dist.shape[1], \"Input is not pairwise dist matrix\"\n",
    "    g = (dist <= parameter).float()\n",
    "    if self_dist:\n",
    "        diag_idx = np.diag_indices(g.shape[0])\n",
    "        g[diag_idx[0], diag_idx[1]] = 0\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6897735",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_from_topk_tensor(similarity, k):\n",
    "    topk_values, topk_indices = torch.topk(similarity, k=k, dim=-1)\n",
    "    mask = torch.zeros_like(similarity)\n",
    "    mask.scatter_(1, topk_indices, 1)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "701b665b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def gen_adj_mat_tensor(data, parameter, metric=\"rbf\"):\n",
    "# def gen_adj_mat_tensor(data, parameter, metric=\"cosine\"):\n",
    "# def gen_adj_mat_tensor(data, parameter, metric=\"adaptive_rbf\"):\n",
    "def gen_adj_mat_tensor(data, parameter, metric=\"hybrid\"):\n",
    "    assert metric in [\"rbf\", \"cosine\", \"adaptive_rbf\", \"hybrid\"], \"Only rbf, cosine, adaptive_rbf, and hybrid supported\"\n",
    "\n",
    "    # Normalize data before computing similarity\n",
    "    data = normalize_data(data)\n",
    "\n",
    "    if metric == \"rbf\":\n",
    "        dist = rbf_distance_torch(data, data, gamma=0.01)\n",
    "    elif metric == \"cosine\":\n",
    "        dist = cosine_distance_torch(data, data)\n",
    "    elif metric == \"adaptive_rbf\":\n",
    "        dist = adaptive_rbf_distance_torch(data, data)\n",
    "    elif metric == \"hybrid\":\n",
    "        dist = hybrid_similarity_torch(data, data, alpha=0.5, gamma=0.01)\n",
    "\n",
    "    g = graph_from_dist_tensor(dist, parameter, self_dist=True)\n",
    "    if metric in [\"rbf\", \"cosine\", \"adaptive_rbf\", \"hybrid\"]:\n",
    "        adj = 1-dist\n",
    "    else:\n",
    "        adj = 1-dist\n",
    "    adj = adj*g \n",
    "    adj_T = adj.transpose(0,1)\n",
    "    I = torch.eye(adj.shape[0])\n",
    "    if cuda:\n",
    "        I = I.cuda()\n",
    "    adj = adj + adj_T*(adj_T > adj).float() - adj*(adj_T > adj).float()\n",
    "    adj = F.normalize(adj + I, p=1)\n",
    "    \n",
    "    # Convert to dense tensor before returning\n",
    "    adj = adj.to_dense()\n",
    "    \n",
    "    return adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "948c84f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def gen_test_adj_mat_tensor(data, trte_idx, parameter, metric=\"rbf\"):\n",
    "# def gen_test_adj_mat_tensor(data, trte_idx, parameter, metric=\"cosine\"):\n",
    "# def gen_test_adj_mat_tensor(data, trte_idx, parameter, metric=\"adaptive_rbf\"):\n",
    "def gen_test_adj_mat_tensor(data, trte_idx, parameter, metric=\"hybrid\"):\n",
    "    assert metric in [\"rbf\", \"cosine\", \"adaptive_rbf\", \"hybrid\"], \"Only rbf, cosine, adaptive_rbf, and hybrid supported\"\n",
    "\n",
    "    # Normalize data before computing similarity\n",
    "    data = normalize_data(data)\n",
    "\n",
    "    adj = torch.zeros((data.shape[0], data.shape[0]))\n",
    "    if cuda:\n",
    "        adj = adj.cuda()\n",
    "    num_tr = len(trte_idx[\"tr\"])\n",
    "    \n",
    "    if metric == \"rbf\":\n",
    "        dist_tr2te = rbf_distance_torch(data[trte_idx[\"tr\"]], data[trte_idx[\"te\"]], gamma=0.01)\n",
    "    elif metric == \"cosine\":\n",
    "        dist_tr2te = cosine_distance_torch(data[trte_idx[\"tr\"]], data[trte_idx[\"te\"]])\n",
    "    elif metric == \"adaptive_rbf\":\n",
    "        dist_tr2te = adaptive_rbf_distance_torch(data[trte_idx[\"tr\"]], data[trte_idx[\"te\"]])\n",
    "    elif metric == \"hybrid\":\n",
    "        dist_tr2te = hybrid_similarity_torch(data[trte_idx[\"tr\"]], data[trte_idx[\"te\"]], alpha=0.5)\n",
    "\n",
    "    g_tr2te = graph_from_dist_tensor(dist_tr2te, parameter, self_dist=False)\n",
    "    adj[:num_tr,num_tr:] = 1-dist_tr2te\n",
    "    adj[:num_tr,num_tr:] = adj[:num_tr,num_tr:]*g_tr2te\n",
    "    \n",
    "    if metric == \"rbf\":\n",
    "        dist_te2tr = rbf_distance_torch(data[trte_idx[\"te\"]], data[trte_idx[\"tr\"]], gamma=0.01)\n",
    "    elif metric == \"cosine\":\n",
    "        dist_te2tr = cosine_distance_torch(data[trte_idx[\"te\"]], data[trte_idx[\"tr\"]])\n",
    "    elif metric == \"adaptive_rbf\":\n",
    "        dist_te2tr = adaptive_rbf_distance_torch(data[trte_idx[\"te\"]], data[trte_idx[\"tr\"]])\n",
    "    elif metric == \"hybrid\":\n",
    "        dist_te2tr = hybrid_similarity_torch(data[trte_idx[\"te\"]], data[trte_idx[\"tr\"]], alpha=0.5)\n",
    "\n",
    "    g_te2tr = graph_from_dist_tensor(dist_te2tr, parameter, self_dist=False)\n",
    "    adj[num_tr:,:num_tr] = 1-dist_te2tr\n",
    "    adj[num_tr:,:num_tr] = adj[num_tr:,:num_tr]*g_te2tr\n",
    "    \n",
    "    adj_T = adj.transpose(0,1)\n",
    "    I = torch.eye(adj.shape[0])\n",
    "    if cuda:\n",
    "        I = I.cuda()\n",
    "    adj = adj + adj_T*(adj_T > adj).float() - adj*(adj_T > adj).float()\n",
    "    adj = F.normalize(adj + I, p=1)\n",
    "    \n",
    "    # Convert to dense tensor before returning\n",
    "    adj = adj.to_dense()\n",
    "    \n",
    "    return adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a897ceba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_dict(folder, model_dict):\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "    for module in model_dict:\n",
    "        torch.save(model_dict[module].state_dict(), os.path.join(folder, module+\".pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "81f900e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_dict(folder, model_dict):\n",
    "    for module in model_dict:\n",
    "        if os.path.exists(os.path.join(folder, module+\".pth\")):\n",
    "#            print(\"Module {:} loaded!\".format(module))\n",
    "            model_dict[module].load_state_dict(torch.load(os.path.join(folder, module+\".pth\"), map_location=\"cuda:{:}\".format(torch.cuda.current_device())))\n",
    "        else:\n",
    "            print(\"WARNING: Module {:} from model_dict is not loaded!\".format(module))\n",
    "        if cuda:\n",
    "            model_dict[module].cuda()    \n",
    "    return model_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d52394b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xavier_init(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.xavier_normal_(m.weight)\n",
    "        if m.bias is not None:\n",
    "           m.bias.data.fill_(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34a0763e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphConvolution(nn.Module):\n",
    "    def __init__(self, in_features, out_features, bias=True):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(in_features, out_features))\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.FloatTensor(out_features))\n",
    "        nn.init.xavier_normal_(self.weight.data)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.fill_(0.0)\n",
    "    \n",
    "    def forward(self, x, adj):\n",
    "        support = torch.mm(x, self.weight)\n",
    "        output = torch.sparse.mm(adj, support)\n",
    "        if self.bias is not None:\n",
    "            return output + self.bias\n",
    "        else:\n",
    "            return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0e4e0466",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN_E(nn.Module):\n",
    "    def __init__(self, in_dim, hgcn_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.gc1 = GraphConvolution(in_dim, hgcn_dim[0])\n",
    "        self.gc2 = GraphConvolution(hgcn_dim[0], hgcn_dim[1])\n",
    "        self.gc3 = GraphConvolution(hgcn_dim[1], hgcn_dim[2])\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        x = self.gc1(x, adj)\n",
    "        x = F.leaky_relu(x, 0.25)\n",
    "        x = F.dropout(x, self.dropout, training=self.training)\n",
    "        x = self.gc2(x, adj)\n",
    "        x = F.leaky_relu(x, 0.25)\n",
    "        x = F.dropout(x, self.dropout, training=self.training)\n",
    "        x = self.gc3(x, adj)\n",
    "        x = F.leaky_relu(x, 0.25)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0e4f7811",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier_1(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.clf = nn.Sequential(nn.Linear(in_dim, out_dim))\n",
    "        self.clf.apply(xavier_init)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.clf(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f31ee90",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VCDN(nn.Module):\n",
    "    def __init__(self, num_view, num_cls, hvcdn_dim):\n",
    "        super().__init__()\n",
    "        self.num_cls = num_cls\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(pow(num_cls, num_view), hvcdn_dim),\n",
    "            nn.LeakyReLU(0.25),\n",
    "            nn.Linear(hvcdn_dim, num_cls)\n",
    "        )\n",
    "        self.model.apply(xavier_init)\n",
    "        \n",
    "    def forward(self, in_list):\n",
    "        num_view = len(in_list)\n",
    "        for i in range(num_view):\n",
    "            in_list[i] = torch.sigmoid(in_list[i])\n",
    "        x = torch.reshape(torch.matmul(in_list[0].unsqueeze(-1), in_list[1].unsqueeze(1)),(-1,pow(self.num_cls,2),1))\n",
    "        for i in range(2,num_view):\n",
    "            x = torch.reshape(torch.matmul(x, in_list[i].unsqueeze(1)),(-1,pow(self.num_cls,i+1),1))\n",
    "        vcdn_feat = torch.reshape(x, (-1,pow(self.num_cls,num_view)))\n",
    "        output = self.model(vcdn_feat)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "be3e2aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model_dict(num_view, num_class, dim_list, dim_he_list, dim_hc, gcn_dopout=0.5):\n",
    "    model_dict = {}\n",
    "    for i in range(num_view):\n",
    "        model_dict[\"E{:}\".format(i+1)] = GCN_E(dim_list[i], dim_he_list, gcn_dopout)\n",
    "        model_dict[\"C{:}\".format(i+1)] = Classifier_1(dim_he_list[-1], num_class)\n",
    "    if num_view >= 2:\n",
    "        model_dict[\"C\"] = VCDN(num_view, num_class, dim_hc)\n",
    "    return model_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d84d1e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_optim(num_view, model_dict, lr_e=1e-4, lr_c=1e-4):\n",
    "    optim_dict = {}\n",
    "    for i in range(num_view):\n",
    "        optim_dict[\"C{:}\".format(i+1)] = torch.optim.Adam(\n",
    "                list(model_dict[\"E{:}\".format(i+1)].parameters())+list(model_dict[\"C{:}\".format(i+1)].parameters()), \n",
    "                lr=lr_e)\n",
    "    if num_view >= 2:\n",
    "        optim_dict[\"C\"] = torch.optim.Adam(model_dict[\"C\"].parameters(), lr=lr_c)\n",
    "    return optim_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4bfbfe94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_trte_data(data_folder, view_list):\n",
    "    num_view = len(view_list)\n",
    "    labels_tr = np.loadtxt(os.path.join(data_folder, \"labels_tr.csv\"), delimiter=',')\n",
    "    labels_te = np.loadtxt(os.path.join(data_folder, \"labels_te.csv\"), delimiter=',')\n",
    "    labels_tr = labels_tr.astype(int)\n",
    "    labels_te = labels_te.astype(int)\n",
    "    data_tr_list = []\n",
    "    data_te_list = []\n",
    "    for i in view_list:\n",
    "        data_tr_list.append(np.loadtxt(os.path.join(data_folder, str(i)+\"_tr.csv\"), delimiter=','))\n",
    "        data_te_list.append(np.loadtxt(os.path.join(data_folder, str(i)+\"_te.csv\"), delimiter=','))\n",
    "    num_tr = data_tr_list[0].shape[0]\n",
    "    num_te = data_te_list[0].shape[0]\n",
    "    data_mat_list = []\n",
    "    for i in range(num_view):\n",
    "        data_mat_list.append(np.concatenate((data_tr_list[i], data_te_list[i]), axis=0))\n",
    "    data_tensor_list = []\n",
    "    for i in range(len(data_mat_list)):\n",
    "        data_tensor_list.append(torch.FloatTensor(data_mat_list[i]))\n",
    "        if cuda:\n",
    "            data_tensor_list[i] = data_tensor_list[i].cuda()\n",
    "    idx_dict = {}\n",
    "    idx_dict[\"tr\"] = list(range(num_tr))\n",
    "    idx_dict[\"te\"] = list(range(num_tr, (num_tr+num_te)))\n",
    "    data_train_list = []\n",
    "    data_all_list = []\n",
    "    for i in range(len(data_tensor_list)):\n",
    "        data_train_list.append(data_tensor_list[i][idx_dict[\"tr\"]].clone())\n",
    "        data_all_list.append(torch.cat((data_tensor_list[i][idx_dict[\"tr\"]].clone(),\n",
    "                                       data_tensor_list[i][idx_dict[\"te\"]].clone()),0))\n",
    "    labels = np.concatenate((labels_tr, labels_te))\n",
    "    \n",
    "    return data_train_list, data_all_list, idx_dict, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2553b619",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_trte_adj_mat(data_tr_list, data_trte_list, trte_idx, adj_parameter):\n",
    "    #adj_metric = \"cosine\" # cosine distance\n",
    "    #adj_metric = \"rbf\"\n",
    "    #adj_metric = \"adaptive_rbf\"\n",
    "    adj_metric = \"hybrid\"\n",
    "    adj_train_list = []\n",
    "    adj_test_list = []\n",
    "    \n",
    "    # Create directory for adjacency matrices if it doesn't exist\n",
    "    adj_dir = \"adjacency_matrices\"\n",
    "    if not os.path.exists(adj_dir):\n",
    "        os.makedirs(adj_dir)\n",
    "    \n",
    "    for i in range(len(data_tr_list)):\n",
    "        adj_parameter_adaptive = cal_adj_mat_parameter(adj_parameter, data_tr_list[i], adj_metric)\n",
    "        adj_train = gen_adj_mat_tensor(data_tr_list[i], adj_parameter_adaptive, adj_metric)\n",
    "        adj_test = gen_test_adj_mat_tensor(data_trte_list[i], trte_idx, adj_parameter_adaptive, adj_metric)\n",
    "        \n",
    "        # Convert to numpy arrays\n",
    "        adj_train_np = adj_train.cpu().numpy()\n",
    "        adj_test_np = adj_test.cpu().numpy()\n",
    "        \n",
    "        # Save to CSV files\n",
    "        np.savetxt(os.path.join(adj_dir, f\"view_{i+1}_train_adj.csv\"), adj_train_np, delimiter=',')\n",
    "        np.savetxt(os.path.join(adj_dir, f\"view_{i+1}_test_adj.csv\"), adj_test_np, delimiter=',')\n",
    "        \n",
    "        adj_train_list.append(adj_train)\n",
    "        adj_test_list.append(adj_test)\n",
    "    \n",
    "    print(f\"\\nAdjacency matrices saved to {adj_dir} directory:\")\n",
    "    for i in range(len(data_tr_list)):\n",
    "        print(f\"View {i+1}:\")\n",
    "        print(f\"- Training adjacency matrix: view_{i+1}_train_adj.csv\")\n",
    "        print(f\"- Test adjacency matrix: view_{i+1}_test_adj.csv\")\n",
    "    \n",
    "    return adj_train_list, adj_test_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8ee065ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(data_list, adj_list, label, one_hot_label, sample_weight, model_dict, optim_dict, train_VCDN=True):\n",
    "    loss_dict = {}\n",
    "    criterion = torch.nn.CrossEntropyLoss(reduction='none')\n",
    "    for m in model_dict:\n",
    "        model_dict[m].train()    \n",
    "    num_view = len(data_list)\n",
    "    for i in range(num_view):\n",
    "        optim_dict[\"C{:}\".format(i+1)].zero_grad()\n",
    "        ci_loss = 0\n",
    "        ci = model_dict[\"C{:}\".format(i+1)](model_dict[\"E{:}\".format(i+1)](data_list[i],adj_list[i]))\n",
    "        ci_loss = torch.mean(torch.mul(criterion(ci, label),sample_weight))\n",
    "        ci_loss.backward()\n",
    "        optim_dict[\"C{:}\".format(i+1)].step()\n",
    "        loss_dict[\"C{:}\".format(i+1)] = ci_loss.detach().cpu().numpy().item()\n",
    "    if train_VCDN and num_view >= 2:\n",
    "        optim_dict[\"C\"].zero_grad()\n",
    "        c_loss = 0\n",
    "        ci_list = []\n",
    "        for i in range(num_view):\n",
    "            ci_list.append(model_dict[\"C{:}\".format(i+1)](model_dict[\"E{:}\".format(i+1)](data_list[i],adj_list[i])))\n",
    "        c = model_dict[\"C\"](ci_list)    \n",
    "        c_loss = torch.mean(torch.mul(criterion(c, label),sample_weight))\n",
    "        c_loss.backward()\n",
    "        optim_dict[\"C\"].step()\n",
    "        loss_dict[\"C\"] = c_loss.detach().cpu().numpy().item()\n",
    "    \n",
    "    return loss_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "39875c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_epoch(data_list, adj_list, te_idx, model_dict):\n",
    "    for m in model_dict:\n",
    "        model_dict[m].eval()\n",
    "    num_view = len(data_list)\n",
    "    ci_list = []\n",
    "    # Get predictions for each view\n",
    "    for i in range(num_view):\n",
    "        ci = model_dict[\"C{:}\".format(i+1)](model_dict[\"E{:}\".format(i+1)](data_list[i],adj_list[i]))\n",
    "        ci_list.append(ci)\n",
    "        # Print individual view predictions\n",
    "        view_prob = F.softmax(ci[te_idx,:], dim=1).data.cpu().numpy()\n",
    "        # print(f\"\\nView {i+1} predictions:\")\n",
    "        # print(\"Predicted classes:\", view_prob.argmax(1))\n",
    "        # print(\"Prediction probabilities:\", view_prob)\n",
    "    \n",
    "    # Get combined prediction\n",
    "    if num_view >= 2:\n",
    "        c = model_dict[\"C\"](ci_list)    \n",
    "    else:\n",
    "        c = ci_list[0]\n",
    "    c = c[te_idx,:]\n",
    "    prob = F.softmax(c, dim=1).data.cpu().numpy()\n",
    "    \n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a018f2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(data_folder, view_list, num_class,\n",
    "               lr_e_pretrain, lr_e, lr_c, \n",
    "               num_epoch_pretrain, num_epoch):\n",
    "    test_inverval = 20\n",
    "    num_view = len(view_list)\n",
    "    dim_hvcdn = pow(num_class,num_view)\n",
    "    if data_folder == 'ROSMAP':\n",
    "        adj_parameter = 2\n",
    "        dim_he_list = [200,200,100]\n",
    "    if data_folder == 'BRCA':\n",
    "        adj_parameter = 10\n",
    "        dim_he_list = [400,400,200]\n",
    "    data_tr_list, data_trte_list, trte_idx, labels_trte = prepare_trte_data(data_folder, view_list)\n",
    "    labels_tr_tensor = torch.LongTensor(labels_trte[trte_idx[\"tr\"]])\n",
    "    onehot_labels_tr_tensor = one_hot_tensor(labels_tr_tensor, num_class)\n",
    "    sample_weight_tr = cal_sample_weight(labels_trte[trte_idx[\"tr\"]], num_class)\n",
    "    sample_weight_tr = torch.FloatTensor(sample_weight_tr)\n",
    "    if cuda:\n",
    "        labels_tr_tensor = labels_tr_tensor.cuda()\n",
    "        onehot_labels_tr_tensor = onehot_labels_tr_tensor.cuda()\n",
    "        sample_weight_tr = sample_weight_tr.cuda()\n",
    "    adj_tr_list, adj_te_list = gen_trte_adj_mat(data_tr_list, data_trte_list, trte_idx, adj_parameter)\n",
    "    dim_list = [x.shape[1] for x in data_tr_list]\n",
    "    model_dict = init_model_dict(num_view, num_class, dim_list, dim_he_list, dim_hvcdn)\n",
    "    for m in model_dict:\n",
    "        if cuda:\n",
    "            model_dict[m].cuda()\n",
    "    \n",
    "    print(\"\\nPretrain GCNs...\")\n",
    "    optim_dict = init_optim(num_view, model_dict, lr_e_pretrain, lr_c)\n",
    "    for epoch in range(num_epoch_pretrain):\n",
    "        train_epoch(data_tr_list, adj_tr_list, labels_tr_tensor, \n",
    "                    onehot_labels_tr_tensor, sample_weight_tr, model_dict, optim_dict, train_VCDN=False)\n",
    "    print(\"\\nTraining...\")\n",
    "    optim_dict = init_optim(num_view, model_dict, lr_e, lr_c)\n",
    "    for epoch in range(num_epoch+1):\n",
    "        train_epoch(data_tr_list, adj_tr_list, labels_tr_tensor, \n",
    "                    onehot_labels_tr_tensor, sample_weight_tr, model_dict, optim_dict)\n",
    "        if epoch % test_inverval == 0:\n",
    "            te_prob = test_epoch(data_trte_list, adj_te_list, trte_idx[\"te\"], model_dict)\n",
    "            print(\"\\nTest: Epoch {:d}\".format(epoch))\n",
    "            if num_class == 2:\n",
    "                print(\"Test ACC: {:.3f}\".format(accuracy_score(labels_trte[trte_idx[\"te\"]], te_prob.argmax(1))))\n",
    "                print(\"Test F1: {:.3f}\".format(f1_score(labels_trte[trte_idx[\"te\"]], te_prob.argmax(1))))\n",
    "                print(\"Test AUC: {:.3f}\".format(roc_auc_score(labels_trte[trte_idx[\"te\"]], te_prob[:,1])))\n",
    "            else:\n",
    "                print(\"Test ACC: {:.3f}\".format(accuracy_score(labels_trte[trte_idx[\"te\"]], te_prob.argmax(1))))\n",
    "                print(\"Test F1 weighted: {:.3f}\".format(f1_score(labels_trte[trte_idx[\"te\"]], te_prob.argmax(1), average='weighted')))\n",
    "                print(\"Test F1 macro: {:.3f}\".format(f1_score(labels_trte[trte_idx[\"te\"]], te_prob.argmax(1), average='macro')))\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "df83c399",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = True if torch.cuda.is_available() else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b751949a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid\n",
      "COS: \n",
      "tensor([[1.0000, 0.9808, 0.9889, 0.9931, 0.9895],\n",
      "        [0.9808, 1.0000, 0.9598, 0.9779, 0.9591],\n",
      "        [0.9889, 0.9598, 1.0000, 0.9863, 0.9908],\n",
      "        [0.9931, 0.9779, 0.9863, 1.0000, 0.9835],\n",
      "        [0.9895, 0.9591, 0.9908, 0.9835, 1.0000]])\n",
      "From rbf_distance_torch\n",
      "RBF: \n",
      "tensor([[0.0000, 0.0000, 0.0673, 0.0128, 0.0520],\n",
      "        [0.0364, 0.0000, 0.1076, 0.0467, 0.0935],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0596, 0.0000, 0.0463],\n",
      "        [0.0000, 0.0000, 0.0194, 0.0000, 0.0000]])\n",
      "Alpha:  tensor(0.0772)\n",
      "\n",
      "Hybrid Similarity Matrix Shape: torch.Size([245, 245])\n",
      "Hybrid Similarity Values (first 5x5):\n",
      "tensor([[0.0028, 0.0027, 0.0050, 0.0032, 0.0045],\n",
      "        [0.0031, 0.0022, 0.0050, 0.0034, 0.0046],\n",
      "        [0.0039, 0.0038, 0.0039, 0.0039, 0.0039],\n",
      "        [0.0029, 0.0029, 0.0050, 0.0029, 0.0045],\n",
      "        [0.0037, 0.0036, 0.0045, 0.0036, 0.0037]])\n",
      "Hybrid\n",
      "COS: \n",
      "tensor([[1.0000, 0.2824, 0.0000, 0.3812, 0.0000],\n",
      "        [0.2824, 1.0000, 0.0000, 0.1610, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000, 0.0000, 0.4646],\n",
      "        [0.3812, 0.1610, 0.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.4646, 0.0000, 1.0000]])\n",
      "From rbf_distance_torch\n",
      "RBF: \n",
      "tensor([[1.7881e-07, 4.9692e-01, 9.2043e-01, 6.3579e-01, 8.5821e-01],\n",
      "        [9.9947e-01, 5.9605e-07, 9.9999e-01, 9.9964e-01, 9.9999e-01],\n",
      "        [9.7560e-01, 9.9836e-01, 2.9802e-07, 9.7099e-01, 7.9665e-01],\n",
      "        [7.9970e-01, 8.1118e-01, 9.4796e-01, 4.7684e-07, 9.5351e-01],\n",
      "        [9.5756e-01, 9.9724e-01, 8.0147e-01, 9.7470e-01, 2.9802e-07]])\n",
      "Alpha:  tensor(0.5779)\n",
      "\n",
      "Hybrid Similarity Matrix Shape: torch.Size([245, 245])\n",
      "Hybrid Similarity Values (first 5x5):\n",
      "tensor([[0.0059, 0.0038, 0.0040, 0.0050, 0.0037],\n",
      "        [0.0046, 0.0045, 0.0033, 0.0040, 0.0033],\n",
      "        [0.0035, 0.0036, 0.0049, 0.0035, 0.0051],\n",
      "        [0.0053, 0.0041, 0.0038, 0.0055, 0.0038],\n",
      "        [0.0035, 0.0036, 0.0052, 0.0035, 0.0050]])\n",
      "Hybrid\n",
      "COS: \n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3069, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.4345, 0.5604, 0.0000, 0.4519],\n",
      "        [0.2431, 0.1420, 0.0000, 0.2673, 0.0000],\n",
      "        [0.0000, 0.0261, 0.3868, 0.0000, 0.4490]])\n",
      "From rbf_distance_torch\n",
      "RBF: \n",
      "tensor([[0.9847, 0.9252, 0.9736, 0.9629, 0.9483],\n",
      "        [0.9931, 0.9992, 0.9999, 0.9986, 0.9997],\n",
      "        [0.9963, 0.7854, 0.7624, 0.9661, 0.7969],\n",
      "        [0.9493, 0.8676, 0.9706, 0.8679, 0.9752],\n",
      "        [0.9959, 0.9293, 0.8671, 0.9683, 0.8014]])\n",
      "Alpha:  tensor(0.8557)\n",
      "\n",
      "Hybrid Similarity Matrix Shape: torch.Size([245, 106])\n",
      "Hybrid Similarity Values (first 5x5):\n",
      "tensor([[0.0054, 0.0050, 0.0053, 0.0052, 0.0052],\n",
      "        [0.0121, 0.0043, 0.0043, 0.0043, 0.0043],\n",
      "        [0.0045, 0.0154, 0.0187, 0.0044, 0.0159],\n",
      "        [0.0133, 0.0095, 0.0054, 0.0137, 0.0054],\n",
      "        [0.0051, 0.0056, 0.0162, 0.0050, 0.0178]])\n",
      "Hybrid\n",
      "COS: \n",
      "tensor([[0.0000, 0.3069, 0.0000, 0.2431, 0.0000],\n",
      "        [0.0000, 0.0000, 0.4345, 0.1420, 0.0261],\n",
      "        [0.0000, 0.0000, 0.5604, 0.0000, 0.3868],\n",
      "        [0.0000, 0.0000, 0.0000, 0.2673, 0.0000],\n",
      "        [0.0000, 0.0000, 0.4519, 0.0000, 0.4490]])\n",
      "From rbf_distance_torch\n",
      "RBF: \n",
      "tensor([[0.9847, 0.9931, 0.9963, 0.9493, 0.9959],\n",
      "        [0.9252, 0.9992, 0.7854, 0.8676, 0.9293],\n",
      "        [0.9736, 0.9999, 0.7624, 0.9706, 0.8671],\n",
      "        [0.9629, 0.9986, 0.9661, 0.8679, 0.9683],\n",
      "        [0.9483, 0.9997, 0.7969, 0.9752, 0.8014]])\n",
      "Alpha:  tensor(0.8557)\n",
      "\n",
      "Hybrid Similarity Matrix Shape: torch.Size([106, 245])\n",
      "Hybrid Similarity Values (first 5x5):\n",
      "tensor([[0.0025, 0.0072, 0.0026, 0.0062, 0.0026],\n",
      "        [0.0025, 0.0027, 0.0091, 0.0046, 0.0029],\n",
      "        [0.0018, 0.0018, 0.0075, 0.0018, 0.0058],\n",
      "        [0.0027, 0.0028, 0.0027, 0.0068, 0.0027],\n",
      "        [0.0018, 0.0019, 0.0068, 0.0019, 0.0067]])\n",
      "Hybrid\n",
      "COS: \n",
      "tensor([[1.0000, 0.9965, 0.9950, 0.9962, 0.9966],\n",
      "        [0.9965, 1.0000, 0.9931, 0.9961, 0.9955],\n",
      "        [0.9950, 0.9931, 1.0000, 0.9935, 0.9965],\n",
      "        [0.9962, 0.9961, 0.9935, 1.0000, 0.9955],\n",
      "        [0.9966, 0.9955, 0.9965, 0.9955, 1.0000]])\n",
      "From rbf_distance_torch\n",
      "RBF: \n",
      "tensor([[5.9605e-08, 1.4425e-02, 2.8779e-02, 8.6204e-03, 1.1926e-02],\n",
      "        [0.0000e+00, 5.9605e-08, 1.9856e-02, 0.0000e+00, 2.1546e-03],\n",
      "        [0.0000e+00, 0.0000e+00, 1.7881e-07, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 1.0186e-02, 2.5595e-02, 5.9605e-08, 8.3519e-03],\n",
      "        [0.0000e+00, 6.9655e-03, 1.8818e-02, 8.2189e-04, 2.3842e-07]])\n",
      "Alpha:  tensor(0.0028)\n",
      "\n",
      "Hybrid Similarity Matrix Shape: torch.Size([245, 245])\n",
      "Hybrid Similarity Values (first 5x5):\n",
      "tensor([[0.0003, 0.0020, 0.0037, 0.0013, 0.0017],\n",
      "        [0.0004, 0.0004, 0.0034, 0.0004, 0.0007],\n",
      "        [0.0006, 0.0006, 0.0006, 0.0006, 0.0006],\n",
      "        [0.0004, 0.0017, 0.0036, 0.0004, 0.0014],\n",
      "        [0.0004, 0.0014, 0.0031, 0.0005, 0.0004]])\n",
      "Hybrid\n",
      "COS: \n",
      "tensor([[1.0000, 0.0851, 0.0377, 0.0457, 0.1317],\n",
      "        [0.0851, 1.0000, 0.0000, 0.1696, 0.0000],\n",
      "        [0.0377, 0.0000, 1.0000, 0.0000, 0.3295],\n",
      "        [0.0457, 0.1696, 0.0000, 1.0000, 0.0000],\n",
      "        [0.1317, 0.0000, 0.3295, 0.0000, 1.0000]])\n",
      "From rbf_distance_torch\n",
      "RBF: \n",
      "tensor([[0.0000e+00, 9.0674e-01, 9.1504e-01, 9.1507e-01, 8.9632e-01],\n",
      "        [9.1214e-01, 0.0000e+00, 9.6884e-01, 8.8554e-01, 9.4116e-01],\n",
      "        [9.8878e-01, 9.9563e-01, 0.0000e+00, 9.9544e-01, 9.7041e-01],\n",
      "        [9.4962e-01, 9.2793e-01, 9.7951e-01, 2.9802e-07, 9.6603e-01],\n",
      "        [8.7525e-01, 9.2486e-01, 7.3050e-01, 9.3109e-01, 2.9802e-07]])\n",
      "Alpha:  tensor(0.6988)\n",
      "\n",
      "Hybrid Similarity Matrix Shape: torch.Size([245, 245])\n",
      "Hybrid Similarity Values (first 5x5):\n",
      "tensor([[0.0085, 0.0040, 0.0037, 0.0037, 0.0044],\n",
      "        [0.0041, 0.0086, 0.0036, 0.0048, 0.0035],\n",
      "        [0.0039, 0.0036, 0.0083, 0.0036, 0.0062],\n",
      "        [0.0036, 0.0046, 0.0034, 0.0080, 0.0033],\n",
      "        [0.0046, 0.0036, 0.0059, 0.0037, 0.0091]])\n",
      "Hybrid\n",
      "COS: \n",
      "tensor([[0.1763, 0.1094, 0.0000, 0.1037, 0.1911],\n",
      "        [0.2570, 0.0229, 0.0000, 0.0947, 0.0000],\n",
      "        [0.0000, 0.0000, 0.3561, 0.0000, 0.3158],\n",
      "        [0.4302, 0.0892, 0.0000, 0.3792, 0.1882],\n",
      "        [0.0000, 0.0107, 0.1802, 0.0000, 0.0455]])\n",
      "From rbf_distance_torch\n",
      "RBF: \n",
      "tensor([[0.9866, 0.9265, 0.8850, 0.9255, 0.8661],\n",
      "        [0.9809, 0.9433, 0.9171, 0.9279, 0.9391],\n",
      "        [0.9994, 0.9907, 0.8866, 0.9884, 0.9154],\n",
      "        [0.9615, 0.9441, 0.9084, 0.8570, 0.8907],\n",
      "        [0.9943, 0.9395, 0.8145, 0.9498, 0.8980]])\n",
      "Alpha:  tensor(0.9315)\n",
      "\n",
      "Hybrid Similarity Matrix Shape: torch.Size([245, 106])\n",
      "Hybrid Similarity Values (first 5x5):\n",
      "tensor([[0.0148, 0.0106, 0.0039, 0.0103, 0.0152],\n",
      "        [0.0212, 0.0059, 0.0043, 0.0105, 0.0044],\n",
      "        [0.0056, 0.0056, 0.0323, 0.0056, 0.0294],\n",
      "        [0.0265, 0.0084, 0.0035, 0.0234, 0.0134],\n",
      "        [0.0057, 0.0062, 0.0187, 0.0054, 0.0087]])\n",
      "Hybrid\n",
      "COS: \n",
      "tensor([[0.1763, 0.2570, 0.0000, 0.4302, 0.0000],\n",
      "        [0.1094, 0.0229, 0.0000, 0.0892, 0.0107],\n",
      "        [0.0000, 0.0000, 0.3561, 0.0000, 0.1802],\n",
      "        [0.1037, 0.0947, 0.0000, 0.3792, 0.0000],\n",
      "        [0.1911, 0.0000, 0.3158, 0.1882, 0.0455]])\n",
      "From rbf_distance_torch\n",
      "RBF: \n",
      "tensor([[0.9866, 0.9809, 0.9994, 0.9615, 0.9943],\n",
      "        [0.9265, 0.9433, 0.9907, 0.9441, 0.9395],\n",
      "        [0.8850, 0.9171, 0.8866, 0.9084, 0.8145],\n",
      "        [0.9255, 0.9279, 0.9884, 0.8570, 0.9498],\n",
      "        [0.8661, 0.9391, 0.9154, 0.8907, 0.8980]])\n",
      "Alpha:  tensor(0.9315)\n",
      "\n",
      "Hybrid Similarity Matrix Shape: torch.Size([106, 245])\n",
      "Hybrid Similarity Values (first 5x5):\n",
      "tensor([[0.0042, 0.0055, 0.0012, 0.0084, 0.0012],\n",
      "        [0.0061, 0.0032, 0.0025, 0.0055, 0.0028],\n",
      "        [0.0025, 0.0025, 0.0159, 0.0025, 0.0090],\n",
      "        [0.0037, 0.0035, 0.0015, 0.0094, 0.0015],\n",
      "        [0.0082, 0.0022, 0.0124, 0.0082, 0.0036]])\n",
      "Hybrid\n",
      "COS: \n",
      "tensor([[1.0000, 0.9970, 0.9962, 0.9978, 0.9970],\n",
      "        [0.9970, 1.0000, 0.9935, 0.9950, 0.9947],\n",
      "        [0.9962, 0.9935, 1.0000, 0.9961, 0.9942],\n",
      "        [0.9978, 0.9950, 0.9961, 1.0000, 0.9962],\n",
      "        [0.9970, 0.9947, 0.9942, 0.9962, 1.0000]])\n",
      "From rbf_distance_torch\n",
      "RBF: \n",
      "tensor([[5.9605e-08, 0.0000e+00, 5.0612e-03, 0.0000e+00, 0.0000e+00],\n",
      "        [1.0078e-02, 5.9605e-08, 1.4855e-02, 3.4903e-03, 1.6604e-03],\n",
      "        [1.9237e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.0579e-02, 6.0553e-03, 1.3712e-02, 0.0000e+00, 1.4983e-03],\n",
      "        [1.3508e-02, 8.4809e-03, 1.7644e-02, 5.7608e-03, 1.7881e-07]])\n",
      "Alpha:  tensor(0.1186)\n",
      "\n",
      "Hybrid Similarity Matrix Shape: torch.Size([245, 245])\n",
      "Hybrid Similarity Values (first 5x5):\n",
      "tensor([[0.0040, 0.0040, 0.0042, 0.0040, 0.0040],\n",
      "        [0.0041, 0.0039, 0.0043, 0.0039, 0.0039],\n",
      "        [0.0041, 0.0040, 0.0041, 0.0040, 0.0040],\n",
      "        [0.0041, 0.0040, 0.0042, 0.0038, 0.0039],\n",
      "        [0.0041, 0.0040, 0.0042, 0.0039, 0.0038]])\n",
      "Hybrid\n",
      "COS: \n",
      "tensor([[1.0000, 0.2531, 0.0000, 0.1070, 0.1107],\n",
      "        [0.2531, 1.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000, 0.1936, 0.0000],\n",
      "        [0.1070, 0.0000, 0.1936, 1.0000, 0.0876],\n",
      "        [0.1107, 0.0000, 0.0000, 0.0876, 1.0000]])\n",
      "From rbf_distance_torch\n",
      "RBF: \n",
      "tensor([[0.0000e+00, 4.1883e-01, 7.0481e-01, 6.0673e-01, 5.9069e-01],\n",
      "        [9.8444e-01, 8.9407e-07, 9.9569e-01, 9.9323e-01, 9.9152e-01],\n",
      "        [9.8028e-01, 9.8925e-01, 2.9802e-07, 9.5855e-01, 9.8604e-01],\n",
      "        [9.3647e-01, 9.5919e-01, 8.9977e-01, 0.0000e+00, 9.2940e-01],\n",
      "        [9.7686e-01, 9.8210e-01, 9.8819e-01, 9.7529e-01, 0.0000e+00]])\n",
      "Alpha:  tensor(0.5837)\n",
      "\n",
      "Hybrid Similarity Matrix Shape: torch.Size([245, 245])\n",
      "Hybrid Similarity Values (first 5x5):\n",
      "tensor([[0.0077, 0.0043, 0.0039, 0.0042, 0.0041],\n",
      "        [0.0051, 0.0053, 0.0038, 0.0038, 0.0038],\n",
      "        [0.0038, 0.0038, 0.0054, 0.0047, 0.0038],\n",
      "        [0.0043, 0.0038, 0.0046, 0.0055, 0.0041],\n",
      "        [0.0041, 0.0035, 0.0035, 0.0039, 0.0050]])\n",
      "Hybrid\n",
      "COS: \n",
      "tensor([[0.0000, 0.2118, 0.0206, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0346, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1083, 0.0000, 0.0000, 0.0898, 0.1187],\n",
      "        [0.2011, 0.1138, 0.0000, 0.1553, 0.0000],\n",
      "        [0.0000, 0.3704, 0.3114, 0.0000, 0.0000]])\n",
      "From rbf_distance_torch\n",
      "RBF: \n",
      "tensor([[0.9884, 0.8643, 0.9071, 0.9305, 0.9563],\n",
      "        [0.9984, 0.9837, 0.9909, 0.9943, 0.9954],\n",
      "        [0.9942, 0.9821, 0.9875, 0.9722, 0.9753],\n",
      "        [0.9865, 0.9473, 0.9748, 0.9459, 0.9837],\n",
      "        [0.9991, 0.9141, 0.9313, 0.9830, 0.9976]])\n",
      "Alpha:  tensor(0.8800)\n",
      "\n",
      "Hybrid Similarity Matrix Shape: torch.Size([245, 106])\n",
      "Hybrid Similarity Values (first 5x5):\n",
      "tensor([[0.0071, 0.0173, 0.0076, 0.0067, 0.0069],\n",
      "        [0.0068, 0.0085, 0.0068, 0.0068, 0.0068],\n",
      "        [0.0124, 0.0068, 0.0068, 0.0113, 0.0128],\n",
      "        [0.0143, 0.0104, 0.0057, 0.0121, 0.0057],\n",
      "        [0.0051, 0.0185, 0.0164, 0.0050, 0.0051]])\n",
      "Hybrid\n",
      "COS: \n",
      "tensor([[0.0000, 0.0000, 0.1083, 0.2011, 0.0000],\n",
      "        [0.2118, 0.0346, 0.0000, 0.1138, 0.3704],\n",
      "        [0.0206, 0.0000, 0.0000, 0.0000, 0.3114],\n",
      "        [0.0000, 0.0000, 0.0898, 0.1553, 0.0000],\n",
      "        [0.0000, 0.0000, 0.1187, 0.0000, 0.0000]])\n",
      "From rbf_distance_torch\n",
      "RBF: \n",
      "tensor([[0.9884, 0.9984, 0.9942, 0.9865, 0.9991],\n",
      "        [0.8643, 0.9837, 0.9821, 0.9473, 0.9141],\n",
      "        [0.9071, 0.9909, 0.9875, 0.9748, 0.9313],\n",
      "        [0.9305, 0.9943, 0.9722, 0.9459, 0.9830],\n",
      "        [0.9563, 0.9954, 0.9753, 0.9837, 0.9976]])\n",
      "Alpha:  tensor(0.8800)\n",
      "\n",
      "Hybrid Similarity Matrix Shape: torch.Size([106, 245])\n",
      "Hybrid Similarity Values (first 5x5):\n",
      "tensor([[0.0027, 0.0027, 0.0048, 0.0066, 0.0027],\n",
      "        [0.0062, 0.0032, 0.0025, 0.0045, 0.0093],\n",
      "        [0.0029, 0.0027, 0.0027, 0.0027, 0.0087],\n",
      "        [0.0027, 0.0029, 0.0048, 0.0061, 0.0029],\n",
      "        [0.0025, 0.0026, 0.0047, 0.0025, 0.0026]])\n",
      "\n",
      "Adjacency matrices saved to adjacency_matrices directory:\n",
      "View 1:\n",
      "- Training adjacency matrix: view_1_train_adj.csv\n",
      "- Test adjacency matrix: view_1_test_adj.csv\n",
      "View 2:\n",
      "- Training adjacency matrix: view_2_train_adj.csv\n",
      "- Test adjacency matrix: view_2_test_adj.csv\n",
      "View 3:\n",
      "- Training adjacency matrix: view_3_train_adj.csv\n",
      "- Test adjacency matrix: view_3_test_adj.csv\n",
      "\n",
      "Pretrain GCNs...\n",
      "\n",
      "Training...\n",
      "\n",
      "Test: Epoch 0\n",
      "Test ACC: 0.519\n",
      "Test F1: 0.683\n",
      "Test AUC: 0.146\n",
      "\n",
      "\n",
      "Test: Epoch 20\n",
      "Test ACC: 0.594\n",
      "Test F1: 0.715\n",
      "Test AUC: 0.708\n",
      "\n",
      "\n",
      "Test: Epoch 40\n",
      "Test ACC: 0.689\n",
      "Test F1: 0.748\n",
      "Test AUC: 0.834\n",
      "\n",
      "\n",
      "Test: Epoch 60\n",
      "Test ACC: 0.792\n",
      "Test F1: 0.788\n",
      "Test AUC: 0.836\n",
      "\n",
      "\n",
      "Test: Epoch 80\n",
      "Test ACC: 0.802\n",
      "Test F1: 0.788\n",
      "Test AUC: 0.850\n",
      "\n",
      "\n",
      "Test: Epoch 100\n",
      "Test ACC: 0.783\n",
      "Test F1: 0.763\n",
      "Test AUC: 0.850\n",
      "\n",
      "\n",
      "Test: Epoch 120\n",
      "Test ACC: 0.783\n",
      "Test F1: 0.800\n",
      "Test AUC: 0.888\n",
      "\n",
      "\n",
      "Test: Epoch 140\n",
      "Test ACC: 0.792\n",
      "Test F1: 0.780\n",
      "Test AUC: 0.876\n",
      "\n",
      "\n",
      "Test: Epoch 160\n",
      "Test ACC: 0.792\n",
      "Test F1: 0.776\n",
      "Test AUC: 0.869\n",
      "\n",
      "\n",
      "Test: Epoch 180\n",
      "Test ACC: 0.792\n",
      "Test F1: 0.788\n",
      "Test AUC: 0.881\n",
      "\n",
      "\n",
      "Test: Epoch 200\n",
      "Test ACC: 0.783\n",
      "Test F1: 0.768\n",
      "Test AUC: 0.884\n",
      "\n",
      "\n",
      "Test: Epoch 220\n",
      "Test ACC: 0.783\n",
      "Test F1: 0.763\n",
      "Test AUC: 0.878\n",
      "\n",
      "\n",
      "Test: Epoch 240\n",
      "Test ACC: 0.783\n",
      "Test F1: 0.772\n",
      "Test AUC: 0.875\n",
      "\n",
      "\n",
      "Test: Epoch 260\n",
      "Test ACC: 0.802\n",
      "Test F1: 0.807\n",
      "Test AUC: 0.885\n",
      "\n",
      "\n",
      "Test: Epoch 280\n",
      "Test ACC: 0.802\n",
      "Test F1: 0.814\n",
      "Test AUC: 0.881\n",
      "\n",
      "\n",
      "Test: Epoch 300\n",
      "Test ACC: 0.783\n",
      "Test F1: 0.768\n",
      "Test AUC: 0.881\n",
      "\n",
      "\n",
      "Test: Epoch 320\n",
      "Test ACC: 0.774\n",
      "Test F1: 0.760\n",
      "Test AUC: 0.881\n",
      "\n",
      "\n",
      "Test: Epoch 340\n",
      "Test ACC: 0.811\n",
      "Test F1: 0.811\n",
      "Test AUC: 0.884\n",
      "\n",
      "\n",
      "Test: Epoch 360\n",
      "Test ACC: 0.792\n",
      "Test F1: 0.796\n",
      "Test AUC: 0.873\n",
      "\n",
      "\n",
      "Test: Epoch 380\n",
      "Test ACC: 0.783\n",
      "Test F1: 0.785\n",
      "Test AUC: 0.878\n",
      "\n",
      "\n",
      "Test: Epoch 400\n",
      "Test ACC: 0.802\n",
      "Test F1: 0.792\n",
      "Test AUC: 0.877\n",
      "\n",
      "\n",
      "Test: Epoch 420\n",
      "Test ACC: 0.811\n",
      "Test F1: 0.818\n",
      "Test AUC: 0.881\n",
      "\n",
      "\n",
      "Test: Epoch 440\n",
      "Test ACC: 0.811\n",
      "Test F1: 0.825\n",
      "Test AUC: 0.878\n",
      "\n",
      "\n",
      "Test: Epoch 460\n",
      "Test ACC: 0.792\n",
      "Test F1: 0.788\n",
      "Test AUC: 0.871\n",
      "\n",
      "\n",
      "Test: Epoch 480\n",
      "Test ACC: 0.802\n",
      "Test F1: 0.792\n",
      "Test AUC: 0.880\n",
      "\n",
      "\n",
      "Test: Epoch 500\n",
      "Test ACC: 0.821\n",
      "Test F1: 0.819\n",
      "Test AUC: 0.888\n",
      "\n",
      "\n",
      "Test: Epoch 520\n",
      "Test ACC: 0.802\n",
      "Test F1: 0.804\n",
      "Test AUC: 0.882\n",
      "\n",
      "\n",
      "Test: Epoch 540\n",
      "Test ACC: 0.783\n",
      "Test F1: 0.781\n",
      "Test AUC: 0.873\n",
      "\n",
      "\n",
      "Test: Epoch 560\n",
      "Test ACC: 0.840\n",
      "Test F1: 0.844\n",
      "Test AUC: 0.882\n",
      "\n",
      "\n",
      "Test: Epoch 580\n",
      "Test ACC: 0.783\n",
      "Test F1: 0.793\n",
      "Test AUC: 0.871\n",
      "\n",
      "\n",
      "Test: Epoch 600\n",
      "Test ACC: 0.802\n",
      "Test F1: 0.811\n",
      "Test AUC: 0.873\n",
      "\n",
      "\n",
      "Test: Epoch 620\n",
      "Test ACC: 0.783\n",
      "Test F1: 0.768\n",
      "Test AUC: 0.871\n",
      "\n",
      "\n",
      "Test: Epoch 640\n",
      "Test ACC: 0.802\n",
      "Test F1: 0.792\n",
      "Test AUC: 0.863\n",
      "\n",
      "\n",
      "Test: Epoch 660\n",
      "Test ACC: 0.821\n",
      "Test F1: 0.816\n",
      "Test AUC: 0.863\n",
      "\n",
      "\n",
      "Test: Epoch 680\n",
      "Test ACC: 0.821\n",
      "Test F1: 0.826\n",
      "Test AUC: 0.863\n",
      "\n",
      "\n",
      "Test: Epoch 700\n",
      "Test ACC: 0.774\n",
      "Test F1: 0.774\n",
      "Test AUC: 0.864\n",
      "\n",
      "\n",
      "Test: Epoch 720\n",
      "Test ACC: 0.802\n",
      "Test F1: 0.796\n",
      "Test AUC: 0.866\n",
      "\n",
      "\n",
      "Test: Epoch 740\n",
      "Test ACC: 0.792\n",
      "Test F1: 0.800\n",
      "Test AUC: 0.873\n",
      "\n",
      "\n",
      "Test: Epoch 760\n",
      "Test ACC: 0.811\n",
      "Test F1: 0.821\n",
      "Test AUC: 0.868\n",
      "\n",
      "\n",
      "Test: Epoch 780\n",
      "Test ACC: 0.802\n",
      "Test F1: 0.817\n",
      "Test AUC: 0.869\n",
      "\n",
      "\n",
      "Test: Epoch 800\n",
      "Test ACC: 0.792\n",
      "Test F1: 0.796\n",
      "Test AUC: 0.866\n",
      "\n",
      "\n",
      "Test: Epoch 820\n",
      "Test ACC: 0.821\n",
      "Test F1: 0.822\n",
      "Test AUC: 0.880\n",
      "\n",
      "\n",
      "Test: Epoch 840\n",
      "Test ACC: 0.802\n",
      "Test F1: 0.804\n",
      "Test AUC: 0.868\n",
      "\n",
      "\n",
      "Test: Epoch 860\n",
      "Test ACC: 0.811\n",
      "Test F1: 0.808\n",
      "Test AUC: 0.867\n",
      "\n",
      "\n",
      "Test: Epoch 880\n",
      "Test ACC: 0.821\n",
      "Test F1: 0.804\n",
      "Test AUC: 0.863\n",
      "\n",
      "\n",
      "Test: Epoch 900\n",
      "Test ACC: 0.783\n",
      "Test F1: 0.781\n",
      "Test AUC: 0.861\n",
      "\n",
      "\n",
      "Test: Epoch 920\n",
      "Test ACC: 0.802\n",
      "Test F1: 0.800\n",
      "Test AUC: 0.878\n",
      "\n",
      "\n",
      "Test: Epoch 940\n",
      "Test ACC: 0.811\n",
      "Test F1: 0.821\n",
      "Test AUC: 0.865\n",
      "\n",
      "\n",
      "Test: Epoch 960\n",
      "Test ACC: 0.802\n",
      "Test F1: 0.807\n",
      "Test AUC: 0.877\n",
      "\n",
      "\n",
      "Test: Epoch 980\n",
      "Test ACC: 0.821\n",
      "Test F1: 0.829\n",
      "Test AUC: 0.881\n",
      "\n",
      "\n",
      "Test: Epoch 1000\n",
      "Test ACC: 0.840\n",
      "Test F1: 0.847\n",
      "Test AUC: 0.874\n",
      "\n",
      "\n",
      "Test: Epoch 1020\n",
      "Test ACC: 0.811\n",
      "Test F1: 0.804\n",
      "Test AUC: 0.870\n",
      "\n",
      "\n",
      "Test: Epoch 1040\n",
      "Test ACC: 0.792\n",
      "Test F1: 0.792\n",
      "Test AUC: 0.866\n",
      "\n",
      "\n",
      "Test: Epoch 1060\n",
      "Test ACC: 0.821\n",
      "Test F1: 0.804\n",
      "Test AUC: 0.866\n",
      "\n",
      "\n",
      "Test: Epoch 1080\n",
      "Test ACC: 0.802\n",
      "Test F1: 0.796\n",
      "Test AUC: 0.853\n",
      "\n",
      "\n",
      "Test: Epoch 1100\n",
      "Test ACC: 0.802\n",
      "Test F1: 0.800\n",
      "Test AUC: 0.864\n",
      "\n",
      "\n",
      "Test: Epoch 1120\n",
      "Test ACC: 0.811\n",
      "Test F1: 0.811\n",
      "Test AUC: 0.871\n",
      "\n",
      "\n",
      "Test: Epoch 1140\n",
      "Test ACC: 0.811\n",
      "Test F1: 0.808\n",
      "Test AUC: 0.868\n",
      "\n",
      "\n",
      "Test: Epoch 1160\n",
      "Test ACC: 0.774\n",
      "Test F1: 0.789\n",
      "Test AUC: 0.865\n",
      "\n",
      "\n",
      "Test: Epoch 1180\n",
      "Test ACC: 0.811\n",
      "Test F1: 0.804\n",
      "Test AUC: 0.860\n",
      "\n",
      "\n",
      "Test: Epoch 1200\n",
      "Test ACC: 0.802\n",
      "Test F1: 0.796\n",
      "Test AUC: 0.861\n",
      "\n",
      "\n",
      "Test: Epoch 1220\n",
      "Test ACC: 0.802\n",
      "Test F1: 0.811\n",
      "Test AUC: 0.864\n",
      "\n",
      "\n",
      "Test: Epoch 1240\n",
      "Test ACC: 0.811\n",
      "Test F1: 0.800\n",
      "Test AUC: 0.856\n",
      "\n",
      "\n",
      "Test: Epoch 1260\n",
      "Test ACC: 0.821\n",
      "Test F1: 0.822\n",
      "Test AUC: 0.870\n",
      "\n",
      "\n",
      "Test: Epoch 1280\n",
      "Test ACC: 0.830\n",
      "Test F1: 0.836\n",
      "Test AUC: 0.866\n",
      "\n",
      "\n",
      "Test: Epoch 1300\n",
      "Test ACC: 0.755\n",
      "Test F1: 0.783\n",
      "Test AUC: 0.850\n",
      "\n",
      "\n",
      "Test: Epoch 1320\n",
      "Test ACC: 0.811\n",
      "Test F1: 0.804\n",
      "Test AUC: 0.883\n",
      "\n",
      "\n",
      "Test: Epoch 1340\n",
      "Test ACC: 0.802\n",
      "Test F1: 0.800\n",
      "Test AUC: 0.870\n",
      "\n",
      "\n",
      "Test: Epoch 1360\n",
      "Test ACC: 0.745\n",
      "Test F1: 0.752\n",
      "Test AUC: 0.856\n",
      "\n",
      "\n",
      "Test: Epoch 1380\n",
      "Test ACC: 0.792\n",
      "Test F1: 0.792\n",
      "Test AUC: 0.862\n",
      "\n",
      "\n",
      "Test: Epoch 1400\n",
      "Test ACC: 0.774\n",
      "Test F1: 0.765\n",
      "Test AUC: 0.855\n",
      "\n",
      "\n",
      "Test: Epoch 1420\n",
      "Test ACC: 0.821\n",
      "Test F1: 0.816\n",
      "Test AUC: 0.878\n",
      "\n",
      "\n",
      "Test: Epoch 1440\n",
      "Test ACC: 0.802\n",
      "Test F1: 0.800\n",
      "Test AUC: 0.873\n",
      "\n",
      "\n",
      "Test: Epoch 1460\n",
      "Test ACC: 0.774\n",
      "Test F1: 0.786\n",
      "Test AUC: 0.859\n",
      "\n",
      "\n",
      "Test: Epoch 1480\n",
      "Test ACC: 0.802\n",
      "Test F1: 0.804\n",
      "Test AUC: 0.875\n",
      "\n",
      "\n",
      "Test: Epoch 1500\n",
      "Test ACC: 0.821\n",
      "Test F1: 0.826\n",
      "Test AUC: 0.871\n",
      "\n",
      "\n",
      "Test: Epoch 1520\n",
      "Test ACC: 0.783\n",
      "Test F1: 0.781\n",
      "Test AUC: 0.855\n",
      "\n",
      "\n",
      "Test: Epoch 1540\n",
      "Test ACC: 0.830\n",
      "Test F1: 0.824\n",
      "Test AUC: 0.873\n",
      "\n",
      "\n",
      "Test: Epoch 1560\n",
      "Test ACC: 0.783\n",
      "Test F1: 0.785\n",
      "Test AUC: 0.860\n",
      "\n",
      "\n",
      "Test: Epoch 1580\n",
      "Test ACC: 0.792\n",
      "Test F1: 0.792\n",
      "Test AUC: 0.865\n",
      "\n",
      "\n",
      "Test: Epoch 1600\n",
      "Test ACC: 0.792\n",
      "Test F1: 0.804\n",
      "Test AUC: 0.861\n",
      "\n",
      "\n",
      "Test: Epoch 1620\n",
      "Test ACC: 0.792\n",
      "Test F1: 0.800\n",
      "Test AUC: 0.865\n",
      "\n",
      "\n",
      "Test: Epoch 1640\n",
      "Test ACC: 0.792\n",
      "Test F1: 0.796\n",
      "Test AUC: 0.866\n",
      "\n",
      "\n",
      "Test: Epoch 1660\n",
      "Test ACC: 0.783\n",
      "Test F1: 0.781\n",
      "Test AUC: 0.858\n",
      "\n",
      "\n",
      "Test: Epoch 1680\n",
      "Test ACC: 0.821\n",
      "Test F1: 0.826\n",
      "Test AUC: 0.878\n",
      "\n",
      "\n",
      "Test: Epoch 1700\n",
      "Test ACC: 0.811\n",
      "Test F1: 0.818\n",
      "Test AUC: 0.872\n",
      "\n",
      "\n",
      "Test: Epoch 1720\n",
      "Test ACC: 0.774\n",
      "Test F1: 0.789\n",
      "Test AUC: 0.860\n",
      "\n",
      "\n",
      "Test: Epoch 1740\n",
      "Test ACC: 0.783\n",
      "Test F1: 0.800\n",
      "Test AUC: 0.868\n",
      "\n",
      "\n",
      "Test: Epoch 1760\n",
      "Test ACC: 0.802\n",
      "Test F1: 0.788\n",
      "Test AUC: 0.856\n",
      "\n",
      "\n",
      "Test: Epoch 1780\n",
      "Test ACC: 0.792\n",
      "Test F1: 0.792\n",
      "Test AUC: 0.866\n",
      "\n",
      "\n",
      "Test: Epoch 1800\n",
      "Test ACC: 0.783\n",
      "Test F1: 0.785\n",
      "Test AUC: 0.862\n",
      "\n",
      "\n",
      "Test: Epoch 1820\n",
      "Test ACC: 0.792\n",
      "Test F1: 0.804\n",
      "Test AUC: 0.869\n",
      "\n",
      "\n",
      "Test: Epoch 1840\n",
      "Test ACC: 0.849\n",
      "Test F1: 0.849\n",
      "Test AUC: 0.879\n",
      "\n",
      "\n",
      "Test: Epoch 1860\n",
      "Test ACC: 0.792\n",
      "Test F1: 0.788\n",
      "Test AUC: 0.863\n",
      "\n",
      "\n",
      "Test: Epoch 1880\n",
      "Test ACC: 0.811\n",
      "Test F1: 0.804\n",
      "Test AUC: 0.862\n",
      "\n",
      "\n",
      "Test: Epoch 1900\n",
      "Test ACC: 0.811\n",
      "Test F1: 0.804\n",
      "Test AUC: 0.864\n",
      "\n",
      "\n",
      "Test: Epoch 1920\n",
      "Test ACC: 0.802\n",
      "Test F1: 0.804\n",
      "Test AUC: 0.877\n",
      "\n",
      "\n",
      "Test: Epoch 1940\n",
      "Test ACC: 0.802\n",
      "Test F1: 0.807\n",
      "Test AUC: 0.873\n",
      "\n",
      "\n",
      "Test: Epoch 1960\n",
      "Test ACC: 0.802\n",
      "Test F1: 0.804\n",
      "Test AUC: 0.865\n",
      "\n",
      "\n",
      "Test: Epoch 1980\n",
      "Test ACC: 0.792\n",
      "Test F1: 0.792\n",
      "Test AUC: 0.856\n",
      "\n",
      "\n",
      "Test: Epoch 2000\n",
      "Test ACC: 0.802\n",
      "Test F1: 0.788\n",
      "Test AUC: 0.857\n",
      "\n",
      "\n",
      "Test: Epoch 2020\n",
      "Test ACC: 0.792\n",
      "Test F1: 0.796\n",
      "Test AUC: 0.865\n",
      "\n",
      "\n",
      "Test: Epoch 2040\n",
      "Test ACC: 0.821\n",
      "Test F1: 0.808\n",
      "Test AUC: 0.871\n",
      "\n",
      "\n",
      "Test: Epoch 2060\n",
      "Test ACC: 0.792\n",
      "Test F1: 0.792\n",
      "Test AUC: 0.867\n",
      "\n",
      "\n",
      "Test: Epoch 2080\n",
      "Test ACC: 0.830\n",
      "Test F1: 0.824\n",
      "Test AUC: 0.873\n",
      "\n",
      "\n",
      "Test: Epoch 2100\n",
      "Test ACC: 0.792\n",
      "Test F1: 0.804\n",
      "Test AUC: 0.862\n",
      "\n",
      "\n",
      "Test: Epoch 2120\n",
      "Test ACC: 0.811\n",
      "Test F1: 0.811\n",
      "Test AUC: 0.871\n",
      "\n",
      "\n",
      "Test: Epoch 2140\n",
      "Test ACC: 0.783\n",
      "Test F1: 0.777\n",
      "Test AUC: 0.852\n",
      "\n",
      "\n",
      "Test: Epoch 2160\n",
      "Test ACC: 0.802\n",
      "Test F1: 0.796\n",
      "Test AUC: 0.875\n",
      "\n",
      "\n",
      "Test: Epoch 2180\n",
      "Test ACC: 0.802\n",
      "Test F1: 0.796\n",
      "Test AUC: 0.865\n",
      "\n",
      "\n",
      "Test: Epoch 2200\n",
      "Test ACC: 0.811\n",
      "Test F1: 0.808\n",
      "Test AUC: 0.865\n",
      "\n",
      "\n",
      "Test: Epoch 2220\n",
      "Test ACC: 0.802\n",
      "Test F1: 0.800\n",
      "Test AUC: 0.866\n",
      "\n",
      "\n",
      "Test: Epoch 2240\n",
      "Test ACC: 0.849\n",
      "Test F1: 0.840\n",
      "Test AUC: 0.873\n",
      "\n",
      "\n",
      "Test: Epoch 2260\n",
      "Test ACC: 0.821\n",
      "Test F1: 0.819\n",
      "Test AUC: 0.869\n",
      "\n",
      "\n",
      "Test: Epoch 2280\n",
      "Test ACC: 0.745\n",
      "Test F1: 0.761\n",
      "Test AUC: 0.854\n",
      "\n",
      "\n",
      "Test: Epoch 2300\n",
      "Test ACC: 0.811\n",
      "Test F1: 0.804\n",
      "Test AUC: 0.872\n",
      "\n",
      "\n",
      "Test: Epoch 2320\n",
      "Test ACC: 0.811\n",
      "Test F1: 0.800\n",
      "Test AUC: 0.862\n",
      "\n",
      "\n",
      "Test: Epoch 2340\n",
      "Test ACC: 0.774\n",
      "Test F1: 0.786\n",
      "Test AUC: 0.862\n",
      "\n",
      "\n",
      "Test: Epoch 2360\n",
      "Test ACC: 0.858\n",
      "Test F1: 0.860\n",
      "Test AUC: 0.873\n",
      "\n",
      "\n",
      "Test: Epoch 2380\n",
      "Test ACC: 0.840\n",
      "Test F1: 0.844\n",
      "Test AUC: 0.884\n",
      "\n",
      "\n",
      "Test: Epoch 2400\n",
      "Test ACC: 0.792\n",
      "Test F1: 0.788\n",
      "Test AUC: 0.856\n",
      "\n",
      "\n",
      "Test: Epoch 2420\n",
      "Test ACC: 0.745\n",
      "Test F1: 0.765\n",
      "Test AUC: 0.859\n",
      "\n",
      "\n",
      "Test: Epoch 2440\n",
      "Test ACC: 0.830\n",
      "Test F1: 0.833\n",
      "Test AUC: 0.873\n",
      "\n",
      "\n",
      "Test: Epoch 2460\n",
      "Test ACC: 0.783\n",
      "Test F1: 0.768\n",
      "Test AUC: 0.852\n",
      "\n",
      "\n",
      "Test: Epoch 2480\n",
      "Test ACC: 0.821\n",
      "Test F1: 0.822\n",
      "Test AUC: 0.861\n",
      "\n",
      "\n",
      "Test: Epoch 2500\n",
      "Test ACC: 0.840\n",
      "Test F1: 0.838\n",
      "Test AUC: 0.869\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":    \n",
    "    data_folder = 'ROSMAP'\n",
    "    view_list = [1,2,3]\n",
    "    num_epoch_pretrain = 500\n",
    "    num_epoch = 2500\n",
    "    lr_e_pretrain = 1e-3  \n",
    "    lr_e = 5e-4\n",
    "    lr_c = 1e-3\n",
    "    \n",
    "    if data_folder == 'ROSMAP':\n",
    "        num_class = 2\n",
    "        # adj_parameter = 5  # Try different values\n",
    "        # dim_he_list = [200,200,100]\n",
    "    if data_folder == 'BRCA':\n",
    "        num_class = 5\n",
    "    \n",
    "    adj_metric = \"cosine\"\n",
    "    \n",
    "    train_test(data_folder, view_list, num_class,\n",
    "               lr_e_pretrain, lr_e, lr_c, \n",
    "               num_epoch_pretrain, num_epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
